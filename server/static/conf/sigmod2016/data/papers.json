entities={
  "387": {
    "title": "A Fast Randomized Algorithm for Multi-Objective Query Optimization", 
    "abstract": "Query plans are compared according to multiple cost metrics in multi-objective query optimization. The goal is to find the set of Pareto plans realizing optimal cost tradeoffs for a given query. So far, only algorithms with exponential time complexity have been proposed for multi-objective query optimization. In this work we present the first polynomial time heuristic for multi-objective query optimization.  Our algorithm is randomized and iterative. It improves query plans via a multi-objective version of hill climbing that applies multiple transformations in each climbing step for maximal efficiency. Based on a locally optimal plan, we approximate the Pareto plan set within the restricted space of plans with similar join orders. We maintain a cache of Pareto-optimal plans for each potentially useful intermediate results to share partial plans that were discovered in different iterations. We show that each iteration of our algorithm performs in expected polynomial time based on an analysis of the expected path length between a random plan and local optima reached by hill climbing. We experimentally show that our algorithm can optimize queries with hundreds of tables and outperforms other randomized algorithms such as the NSGA-II genetic algorithm over a wide range of scenarios. ", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Immanuel Trummer"
      }, 
      {
        "name": "Christoph Koch"
      }
    ], 
    "type": "Research", 
    "id": "387"
  }, 
  "922": {
    "title": "A Hybrid Approach to Functional Dependency Discovery", 
    "abstract": "Functional dependencies are structural metadata that can be used for schema normalization, data integration, data cleansing, and many other data management tasks. Despite their importance, the functional dependencies of a specific dataset are usually unknown and almost impossible to discover manually. For this reason, database research has proposed various algorithms for functional dependency discovery. None, however, are able to process datasets of typical real-world size, e.g., datasets with more than 50 attributes and a million records. We present a hybrid discovery algorithm called HyFD, which combines fast approximation techniques with efficient validation techniques in order to find all minimal functional dependencies in a given dataset. While operating on compact data structures, HyFD not only outperforms all existing approaches, it also scales to much larger datasets.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Thorsten Papenbrock"
      }, 
      {
        "name": "Felix Naumann"
      }
    ], 
    "type": "Research,", 
    "id": "922"
  }, 
  "377": {
    "title": "A Hybrid B+-Tree as Solution for In-Memory Indexing on CPU-GPU Heterogeneous Computing Platforms", 
    "abstract": "An in-memory indexing tree is a critical component of many databases. Modern many-core processors, such as GPUs, are offering tremendous amounts of computing power which makes them an attractive choice for accelerating indexing. However, the memory available to the accelerating co-processor is rather limited and expensive in comparison to the memory available to the CPU. This drawback is a barrier to exploit the computing power of co-processors for arbitrarily large index trees. In this paper, we propose a novel design for a B+-tree based on the heterogeneous computing platform and the hybrid memory architecture found in GPUs. Furthermore, we propose a hybrid CPU-GPU B+-tree, \u00d0 HB+-tree, \u00d0 which targets high search throughput use cases. Unique to our design is the joint and simultaneous use of computing and memory resources of CPU-GPU systems. Our experiments show that our HB+-tree can perform up to 240 million index queries per second, which is 2.4X higher than our CPU optimized solution.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Amirhesam Shahvarani"
      }, 
      {
        "name": "Hans-Arno Jacobsen"
      }
    ], 
    "type": "Research", 
    "id": "377"
  }, 
  "363": {
    "title": "A Study of Sorting Algorithms on Approximate Memory", 
    "abstract": "Hardware evolution has been one of the driving factors for the redesign of database systems. Recently, approximate storage emerges in the area of computer architecture. It trades o_ precision for better performance or energy consumption, or both. Previous studies have demonstrated the bene\u00dets of approximate storage on applications that are tolerant to imprecision such as image processing. However, it is still an open problem whether and how approximate storage can be used for applications that do not expose such intrinsic tolerance. In this paper, we study one of the most basic operation in database\u00d0sorting on a hybrid storage system with both precise storage and approximate storage. Particularly, we start with a study of three common sorting algorithms on approximate storage. Experimental results show that a 95% sorted sequence can be obtained with up to 40% reduction in total write latencies. Thus, we exploit a novel approx-re\u00dene execution mechanism to improve the performance of sorting algorithms on the hybrid storage system to produce precise results. Our optimization gains the performance bene\u00dets by o_oading the sort operation to approximate storage, followed by an e_cient re\u00denement to resolve the unsortedness on the output of the approximate storage. Our experiments show that our approx-re\u00dene can reduce the total memory access time by up to 10%. These studies shed light on the potential of approximate hardware for improving the performance of applications with the requirement of precise results.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Bingsheng He"
      }, 
      {
        "name": "Shunning Jiang"
      }, 
      {
        "name": "Shuang Chen"
      }, 
      {
        "name": "Xueyan Tang"
      }
    ], 
    "type": "Research", 
    "id": "363"
  }, 
  "434": {
    "title": "AT-GIS: Highly Parallel Spatial Query Processing with Associative Transducers", 
    "abstract": "The rise of crowd-sourcing projects, such as OpenStreetMap, and high-resolution sensing capabilities have led to spatial datasets of increasing size and complexity. Users in many applications domains, including urban planning, transportation, and environmental science, therefore want to execute analytical queries over these continuously updated spatial datasets. Current solutions for large-scale spatial query processing either rely on extensions to RDBMS, which entails expensive loading and indexing phases whenever the data changes, or distributed map/reduce frameworks, which require expensive compute clusters. Both solutions struggle to manage the sequential bottleneck of parsing complex, hierarchical spatial data formats, which typically dominates query execution time. Our goal is to fully exploit the parallelism offered by modern multi-core CPUs during parsing and query execution, thus providing the performance of a cluster with the resources of a single machine.  We describe AT-GIS, a highly-parallel spatial query processing system that scales linearly to a large number of CPU cores. AT-GIS integrates the parsing and querying of spatial data using a new computational abstraction called Associative Transducers (ATs). ATs can form a single data-parallel pipeline for computation without requiring the spatial input data to be split into logically independent blocks.  Using ATs, AT-GIS can execute, in parallel, spatial query operators on the raw input data in multiple formats, without any pre-processing. On a single 64-core machine, AT-GIS provides 3x the performance of an 8-node Hadoop cluster with 192 cores for containment queries, and 10x for aggregation queries.  We also show that AT-GIS scales regardless of the size or the skew of the input data. ", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Peter Ogden"
      }, 
      {
        "name": "Peter Pietzuch"
      }, 
      {
        "name": "David Thomas"
      }
    ], 
    "type": "Research", 
    "id": "434"
  }, 
  "416": {
    "title": "Accelerating Relational Databases by Leveraging Remote Memory and RDMA", 
    "abstract": "Memory is a crucial resource in relational databases (RDBMSs). When there is insufficient memory, RDBMSs are forced to use slower media such as SSDs or HDDs, which can significantly degrade workload performance. Cloud database services are deployed in data centers where network adapters supporting remote direct memory access (RDMA) at low latency and high bandwidth are becoming prevalent. We study the novel problem of how a single server RDBMS, whose memory demands exceed locally-available memory, can leverage available remote memory in the cluster accessed via RDMA to improve query performance. We expose available memory on a remote server using a lightweight file API that allows a single server RDBMS to leverage the benefits of remote memory with modest changes. We identify and implement several novel scenarios to demonstrate these benefits, and address design challenges that are crucial for efficient implementation. We implemented the scenarios in a commercial RDBMS engine and present the first end-to-end study to demonstrate benefits of remote memory for a variety of micro-benchmarks and industry-standard benchmarks. Compared to using disks when memory is insufficient, we improve the throughput and latency of queries with short reads and writes by 3X to 10X, while improving the latency of multiple TPC-H and TPC-DS queries by 2X to 100X.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Feng Li"
      }, 
      {
        "name": "Sudipto Das"
      }, 
      {
        "name": "Manoj Syamala"
      }, 
      {
        "name": "Vivek Narasayya"
      }
    ], 
    "type": "Research", 
    "id": "416"
  }, 
  "393": {
    "title": "Adaptive Indexing over Encrypted Data", 
    "abstract": "Today, outsourcing heavy query processing tasks to remote servers becomes a viable option; such outsourcing calls for encrypting data so as to render it secure against adversaries and/or untrusted servers. At the same time, to be efficiently managed, outsourced data should be indexed, while current trends call for adaptive indexing as side-effect of query processing. Yet current trends in encryption propose computationally heavy encryption schemes that render such outsourcing unattractive albeit secure; an alternative, Order-Preserving Encryption Scheme (OPES), intentionally preserves and reveals the order in the data, hence is unattractive from the security viewpoint. In this paper, we propose and analyze a lightweight and indexable encryption scheme, which provides higher security than OPES, while it fits with the philosophy of adaptive indexing. Our scheme is based on algebraic operations and allows for equality and range queries to be efficiently evaluated over encrypted data; thereby it enables incremental adaptive indexing, without leaking order information and without prohibitive overhead, as our extensive experimental study demonstrates.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Panagiotis Karras"
      }, 
      {
        "name": "Saad Malhotra"
      }, 
      {
        "name": "Rudrika Bhatt"
      }, 
      {
        "name": "Artyom Nikitin"
      }, 
      {
        "name": "Denis Antyukhov"
      }, 
      {
        "name": "Stratos Idreos"
      }
    ], 
    "type": "Research", 
    "id": "393"
  }, 
  "928": {
    "title": "Adaptive Logging: Optimizing Logging and Recovery Costs in Distributed In-memory Databases", 
    "abstract": "By maintaining the data in main memory, in-memory databases dramatically reduce the I/O cost of transaction processing. However, for recovery purposes, in-memory systems still need to flush the log to disk, which incurs a substantial number of I/Os. Recently, command logging has been employed to replace the traditional data log (e.g., ARIES logging) in in-memory databases. Instead of recording how the tuples are updated, command logging only tracks the transactions that are being executed, thereby effectively reducing the size of the log and improving the performance. However, when there is a failure, all the transactions in the log after the last checkpoint must be redone sequentially and this significantly increases the cost of recovery.  In this paper, we first extend the command logging technique to a distributed system, where all the nodes can perform their recovery in parallel. We show that in a distributed system, the only bottleneck of recovery caused by command logging is the synchronization process that attempts to resolve the data dependency among the transactions. We then propose an adaptive logging approach by combining data logging and command logging. The percentage of data logging versus command logging becomes a tuning knob between the performance of transaction processing and recovery to meet different OLTP requirements, and a model is proposed to guide such tuning. Our experimental study compares the performance of our proposed adaptive logging, ARIES-style data logging and command logging on top of H-Store. The results show that adaptive logging can achieve a 10x boost for recovery and a transaction throughput that is comparable to that of command logging.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Chang Yao"
      }, 
      {
        "name": "Divyakant Agrawal"
      }, 
      {
        "name": "Gang Chen"
      }, 
      {
        "name": "Beng Chin Ooi"
      }, 
      {
        "name": "Sai Wu"
      }
    ], 
    "type": "Research,", 
    "id": "928"
  }, 
  "400": {
    "title": "Adding Counting Quantifiers to Graph Patterns", 
    "abstract": "This paper proposes quantified graph patterns (QGPs), an extension of graph patterns by supporting simple counting quantifiers on edges. We show that QGPs naturally express universal and existential quantification, numeric and ratio aggregates, as well as negation. Better still, the increased expressive power does not come with a much higher price. We show that quantified matching, i.e., graph pattern matching with QGPs, remains \\NP-complete in the absence of negation, and is DP-complete for general QGPs. We show how quantified matching can be conducted by incorporating quantifier check into conventional subgraph isomorphism methods. We also develop parallel scalable algorithms for quantified matching. As an application of QGPs, we introduce quantified graph association rules defined with QGPs, to identify potential customers in social media marketing. Using real-life and synthetic graphs, we experimentally verify the effectiveness of QGPs and the scalability of our algorithms.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Wenfei Fan"
      }, 
      {
        "name": "YINGHUI WU"
      }, 
      {
        "name": "Jingbo Xu"
      }
    ], 
    "type": "Research", 
    "id": "400"
  }, 
  "892": {
    "title": "Ambry: LinkedIn's Scalable Geo-Distributed Object Store", 
    "abstract": "The infrastructure beneath a worldwide social network has to serve billions of variable-sized media objects such as photos, videos, and audios, continually.  These objects must be stored and served with low latency and high throughput by a system that is geo-distributed, highly scalable, and load-balanced. Existing file systems and object stores face several challenges when serving such large objects. We present Ambry, a production-quality system for storing large immutable data (called blobs). Ambry is designed in a decentralized way and leverages techniques such as logical blob grouping, asynchronous replication, rebalancing mechanisms, zero-cost failure detection, and OS caching. Ambry has been running in LinkedIn's production environment for the past 2 years, serving up to 10K requests per second across more than 400 million users. Our experimental evaluation reveals that Ambry offers high efficiency (utilizing up to 88\\% of the network bandwidth), responsiveness with low latency (less than 50 ms for a 1 MB object), and load balancing (improving the imbalance of requests by 8x-10x).", 
    "subtype": "Industrial", 
    "authors": [
      {
        "name": "Shadi Abdollahian Noghabi"
      }, 
      {
        "name": "Sriram Subramanian"
      }, 
      {
        "name": "Priyesh Narayanan"
      }, 
      {
        "name": "Sivabalan Narayanan"
      }, 
      {
        "name": "Gopalakrishna Holla"
      }, 
      {
        "name": "Mammad Zadeh"
      }, 
      {
        "name": "Tianwei Li"
      }, 
      {
        "name": "Indranil Gupta"
      }, 
      {
        "name": "Roy Campbell"
      }
    ], 
    "type": "Industrial", 
    "id": "892"
  }, 
  "407": {
    "title": "An Effective Syntax for Bounded Relational Queries", 
    "abstract": "A query Q is boundedly evaluable under a form of access constraints \\A if for all datasets D that satisfy \\A, there exists a subset D_Q of D such that Q(D) = Q(D_Q), and the size of D_Q and time for identifying D_Q are both independent of the size |D| of D. That is, we can compute Q(D) by accessing a bounded amount of data no matter how big D grows. However, while desirable, it is undecidable to determine whether a relational algebra (\\RA) query is bounded under \\A. In light of the undecidability, this paper develops an effective syntax for bounded \\RA queries.  We identify a class of covered \\RA queries such that under \\A, (a) every boundedly evaluable \\RA query is equivalent to a covered query, (b) every covered \\RA query is boundedly evaluable, and (c) it takes \\PTIME in |Q| and |\\A| to check whether Q is covered by \\A. We provide quadratic-time algorithms to check the coverage of Q, and to generate a bounded query plan for covered Q.  We also study a new optimization problem for answering covered queries with minimum access constraints, and develop its complexity and algorithms. These provide both fundamental results and practical algorithms for making use of bounded evaluability.  Using real-life data, we experimentally verify that a large number of \\RA queries in practice are covered, and that bounded query plans improve \\RA query evaluation by orders of magnitude.  ", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Yang Cao"
      }, 
      {
        "name": "Wenfei Fan"
      }
    ], 
    "type": "Research", 
    "id": "407"
  }, 
  "381": {
    "title": "An Efficient MapReduce Cube Algorithm for Varied Data Distributions", 
    "abstract": "Data cubes allow users to discover insights from their data and are commonly used in data analysis. While very useful, the data cube is expensive to compute, in particular when the input relation is very large. To address this problem, we consider cube computation in MapReduce, the popular paradigm for distributed big data processing, and present an efficient algorithm for computing cubes over large data sets. We show that our new algorithm consistently performs better than the previous solutions. In particular, existing techniques for cube computation in MapReduce suffer from sensitivity to the distribution of the input data and their performance heavily depends on whether or not, and how exactly, the data is skewed. In contrast, the cube algorithm that we present here is resilient and significantly outperforms previous solutions for varying data distributions. At the core of our solution is a dedicated data structure called the Skews and Partitions Sketch (SP-Sketch for short). The SP-Sketch is compact in size and fast to compute, and records all needed information for identifying skews and effectively partitioning the workload between the machines. Our algorithm uses the sketch to speed up computation and minimize communication overhead. Our theoretical analysis and thorough experimental study demonstrate the feasibility and efficiency of our solution, including comparisons to state of the art tools for big data processing such as Pig and Hive.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Eyal Altshuler"
      }, 
      {
        "name": "Tova Milo"
      }
    ], 
    "type": "Research", 
    "id": "381"
  }, 
  "376": {
    "title": "An Experimental Comparison of Thirteen Relational Equi-Joins in Main Memory", 
    "abstract": "Relational equi-joins are at the heart of almost every query plan. They have been studied, improved, and reexamined on a regular basis since the existence of the database community. In the past four years several new join algorithms have been proposed and experimentally evaluated. Some of those papers contradict each other in their experimental findings. This makes it surprisingly hard to answer a very simple question: what is the fastest join algorithm in 2015?  In this paper we will try to develop an answer. We start with an end-to-end black box comparison of the most important methods. Afterwards, we inspect the internals of these algorithms in a white box comparison. We derive improved variants of state-of-the-art join algorithms by applying optimizations like~software-write combine buffers, various hash table implementations, as well as NUMA-awareness in terms of data placement and scheduling. We also inspect various radix partitioning strategies. Eventually, we are in the position to perform a comprehensive comparison of thirteen different join algorithms. We factor in scaling effects in terms of size of the input datasets, the number of threads, different page sizes, and data distributions. Furthermore, we analyze the impact of various joins on an (unchanged) TPC-H query.  Finally, we conclude with a list of major lessons learned from our study and a guideline for practitioners implementing massive main-memory joins. As is the case with almost all algorithms in databases, we will learn that there is no single best join algorithm. Each algorithm has its strength and weaknesses and shines in different areas of the parameter space. ", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Stefan Schuh"
      }, 
      {
        "name": "Jens Dittrich"
      }, 
      {
        "name": "Xiao Chen"
      }
    ], 
    "type": "Research", 
    "id": "376"
  }, 
  "414": {
    "title": "Augmented Sketch: Faster and More Accurate Stream Processing", 
    "abstract": "Approximated algorithms are often used to estimate the frequency of items on high volume, fast data streams. The most common ones are variations of Count-Min sketch, which use sub-linear space for the count, but can produce errors in the counts of the most frequent items and can misclassify low-frequency items. In this paper, we improve the accuracy of sketch-based algorithms by increasing the frequency estimation accuracy of the most frequent items and reducing the possible misclassification of low-frequency items, while also improving the overall throughput.  Our solution, called Augmented Sketch (ASketch), is based on a pre-filtering stage that dynamically identifies and aggregates the most frequent items. Items overflowing the pre-filtering stage are processed using a conventional sketch algorithm, thereby making the solution general and applicable in a wide range of contexts. The pre-filtering stage can be efficiently implemented with SIMD instructions on multi-core machines and can be further parallelized through pipeline parallelism where the filtering stage runs in one core and the sketch algorithm runs in another core.   ASketch outperforms existing stream processing techniques in both throughput and accuracy. We also demonstrate the linear scalability of ASketch with SPMD (i.e., single program, multiple data) parallelism.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Pratanu Roy"
      }, 
      {
        "name": "Arijit Khan"
      }, 
      {
        "name": "Gustavo Alonso"
      }
    ], 
    "type": "Research", 
    "id": "414"
  }, 
  "883": {
    "title": "Automated Demand-driven Resource Scaling in Relational Database-as-a-Service", 
    "abstract": "Relational Database-as-a-Service (DaaS) platforms today support the abstraction of a resource container that guarantees a fixed amount of resources. Tenants of the platform are responsible to select a container size suitable for their workloads, which they can change to leverage the cloud\u00d5s elasticity. However, automating this task is daunting for most tenants since workloads and resource requirements can vary significantly within minutes to hours, and container sizes vary by orders of magnitude both in the amount of resources as well as monetary cost. We present a solution to enable a DaaS to auto-scale container sizes on behalf of its tenants. A key problem we address is estimating resource demands for arbitrary SQL workloads in an RDBMS. Approaches to auto-scale stateless services, such as web servers, that rely on historical resource utilization as the primary signal often perform poorly in stateful database servers which are significantly more complex. We derive a set of robust signals from database engine telemetry and show how to combine these signals to significantly improve accuracy of demand estimation for database workloads. Our solution raises the abstraction for tenants by allowing them to reason about monetary budget and query latency rather than resource provisioning. We prototyped our approach in Microsoft Azure SQL Database and ran extensive experiments using workloads with realistic time-varying resource demand patterns obtained from production traces. Compared to an approach that uses only resource utilization to estimate demand, our approach results in 1.5_ to 3_ lower monetary costs while achieving comparable query latencies.", 
    "subtype": "Industrial", 
    "authors": [
      {
        "name": "Sudipto Das"
      }, 
      {
        "name": "Feng Li"
      }, 
      {
        "name": "Vivek Narasayya"
      }, 
      {
        "name": "Christian Konig"
      }
    ], 
    "type": "Industrial", 
    "id": "883"
  }, 
  "383": {
    "title": "Automatic Generation of Normalized Relational Schemas from Key-Value Data", 
    "abstract": "Self-describing key-value data formats such as JSON are becoming increasingly popular as application developers choose to avoid the rigidity imposed by the relational model. Database systems designed for these self-describing formats, such as MongoDB, encourage users to use denormalized, heavily nested data models so that relationships across records and other schema information need not be predefined or standardized. Such data models contribute to long-term development complexity, as their lack of explicit entity and relationship tracking burdens new developers unfamiliar with the dataset. Furthermore, the large amount of data repetition present in such data layouts can introduce update anomalies and poor scan performance, which reduce both the quality and performance of analytics over the data.   In this paper we present an algorithm that automatically transforms the denormalized, nested data commonly found in NoSQL systems into traditional relational data that can be stored in a standard RDBMS. This process includes a schema generation algorithm that discovers relationships across the attributes of the denormalized datasets in order to organize those attributes into relational tables. It further includes a matching algorithm that discovers sets of attributes that represent overlapping entities and merges those sets together. Combined, these algorithms reduce data repetition, enable the end-user to use traditional data analysis tools designed to work with relational data, accelerate scan-based analysis algorithms over the data, and help users gain a semantic understanding of complex, nested datasets.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Daniel Abadi"
      }, 
      {
        "name": "Michael DiScala"
      }
    ], 
    "type": "Research", 
    "id": "383"
  }, 
  "958": {
    "title": "Big Data Analytics with Datalog Queries on Spark", 
    "abstract": "There is great interest in exploiting the opportunity provided by cloud computing platforms for large-scale analytics.  Among these platforms, Apache Spark is growing in popularity for machine learning and graph analytics. Developing efficient complex analytics in Spark requires deep understanding of both the algorithm at hand and the Spark API or subsystem APIs (e.g., SparkSQL, GraphX).  Our BigDatalog system addresses the problem by providing concise declarative specification of complex queries amenable to efficient evaluation.  Towards this goal, we propose compilation and optimization techniques that tackle the important problem of efficiently supporting recursion in Spark.  We perform an experimental comparison with other state-of-the-art large-scale Datalog systems and verify the efficacy of our techniques and effectiveness of Spark in supporting Datalog-based analytics.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Alexander Shkapsky"
      }, 
      {
        "name": "Mohan Yang"
      }, 
      {
        "name": "Matteo Interlandi"
      }, 
      {
        "name": "Hsuan Chiu"
      }, 
      {
        "name": "Tyson Condie"
      }, 
      {
        "name": "Carlo Zaniolo"
      }
    ], 
    "type": "Research,", 
    "id": "958"
  }, 
  "961": {
    "title": "Bridging the Archipelago between Row-Stores and Column-Stores for Hybrid Workloads", 
    "abstract": "Data-intensive applications seek to obtain new insights in real-time by analyzing a combination of historical data sets alongside recently collected data. This means that to support such hybrid workloads, database management systems (DBMSs) need to handle both fast ACID transactions and complex analytical queries on the same database. But the current trend is to use specialized systems that are optimized for only one of these workloads, and thus require an organization to maintain separate copies of the database. This adds additional cost to deploying a database application in terms of both storage and administration overhead.  To overcome this barrier, we present a hybrid DBMS architecture that efficiently supports varied workloads on the same database. Our approach differs from previous methods in that we use a single execution engine that is oblivious to the storage layout of data without sacrificing the performance benefits of the specialized systems. This obviates the need to maintain separate copies of the database in multiple independent systems. We also present a technique to continuously evolve the database\u00d5s physical storage layout by analyzing the queries\u00d5 access patterns and choosing the optimal layout for different segments of data within the same table. To evaluate this work, we implemented our architecture in an in-memory DBMS. Our results show that our approach delivers up to 3_ higher through- put compared to static storage layouts across different workloads. We also demonstrate that our continuous adaptation mechanism allows the DBMS to achieve a near-optimal layout for an arbitrary workload without requiring any manual tuning.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Joy Arulraj"
      }, 
      {
        "name": "Andy Pavlo"
      }, 
      {
        "name": "Prashanth Menon"
      }
    ], 
    "type": "Research,", 
    "id": "961"
  }, 
  "919": {
    "title": "Building the Enterprise Fabric for Big Data with Vertica and Spark Integration", 
    "abstract": "Enterprise customers are increasingly requiring greater flexibility in the way they access and process their Big Data while at the same time they continue to request advanced analytics and access to diverse data sources. Yet they still require the robustness of enterprise class analytics for their mission-critical data.  In this abstract, we present our initial efforts toward a solution that satisfies the above requirements by integrating the HPE Vertica enterprise database with Apache Spark's open source big data computation engine. In particular, it enables transferring data between Vertica and Spark and deploying ML models created by Spark into Vertica for predictive analytics on Vertica data. This integration provides a fabric on which our customers get the best of both worlds: it extends Vertica's extensive SQL analytics capabilities with Spark's machine learning library (MLlib), giving Vertica users access to a wide range of ML functions; it also enables customers to leverage Spark as an advanced ETL engine for all data stored in their Spark cluster that require the guarantees offered by Vertica. ", 
    "subtype": "Industrial", 
    "authors": [
      {
        "name": "Jeff LeFevre"
      }, 
      {
        "name": "Rui Liu"
      }, 
      {
        "name": "Edward Ma"
      }, 
      {
        "name": "Malu Castellanos"
      }, 
      {
        "name": "Cornelio Inigo"
      }, 
      {
        "name": "Lupita Paz"
      }, 
      {
        "name": "Meichun Hsu"
      }
    ], 
    "type": "Industrial", 
    "id": "919"
  }, 
  "874": {
    "title": "Closing the Schema and Performance Gap between SQL and NoSQL", 
    "abstract": "Oracle release 12cR1 supports JSON data management that enables users to store, index and query JSON data along with relational data. The integration of the JSON data model into the RDBMS allows a new paradigm of data management where data is storable, indexable and queryable without upfront schema definition. We call this new paradigm Flexible Schema Data Management (FSDM). In this paper, we present enhancements to Oracle's JSON data management in the upcoming 12cR2 release. We present JSON DataGuide, an auto-computed dynamic soft schema for JSON collections that closes the functional gap between the fixed-schema SQL world and the schema-less NoSQL world.  We present a self-contained query friendly binary format for encoding JSON (OSON) to close the query performance gap between schema-encoded relational data and schema free JSON textual data. The addition of these new features makes the Oracle RDBMS well suited to both fixed-schema SQL and flexible-schema NoSQL use cases, and allows users to freely mix the two paradigms in a single data management system.", 
    "subtype": "Industrial", 
    "authors": [
      {
        "name": "Zhen Hua Liu"
      }, 
      {
        "name": "Beda Hammerschmidt"
      }, 
      {
        "name": "doug. Mcmahon"
      }, 
      {
        "name": "ying Lu"
      }, 
      {
        "name": "hui Chang"
      }
    ], 
    "type": "Industrial", 
    "id": "874"
  }, 
  "423": {
    "title": "Constraint-Variance Tolerant Data Repairing", 
    "abstract": "Integrity constraints, guiding the cleaning of dirty data, are often found to be imprecise as well. Existing studies con- sider the inaccurate constraints that are oversimplified, and thus refine the constraints via inserting more predicates (at- tributes). We note that imprecise constraints could not only be oversimplified so that correct data are erroneously iden- tified as violations, but also could be overrefined that the constraints overfit the data and fail to identify true viola- tions. In the latter case, deleting excessive predicates may apply. To address the aforesaid oversimplified and overrefined constraint inaccuracies, in this paper, we propose to repair data by allowing a small variation (with both predicate in- sertion and deletion) on the constraints. A novel _-tolerant repair model is introduced, which returns a (minimum) data repair that satisfies at least one variant of the constraints (with constraint variation no greater than _ compared to the given constraints). To efficiently repair data among var- ious constraint variants, we propose a single round, sharing enabled approach. Results on real data sets demonstrate that our proposal can capture more accurate data repairs compared to the existing methods with/without constraint repairs.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Shaoxu Song"
      }, 
      {
        "name": "Han Zhu"
      }, 
      {
        "name": "Jianmin Wang"
      }
    ], 
    "type": "Research", 
    "id": "423"
  }, 
  "432": {
    "title": "Continuous Influence Maximization: What Discounts Should We Offer to Social Network Users?", 
    "abstract": "Imagine we are introducing a new product through a social network, where for each user in the network the purchase probability curve with respect to discount can be assumed, what discount should we offer to those social network users so that the adoption of the product is maximized in expectation under a predefined budget? Surprisingly, this appealing problem cannot be answered by the existing influence maximization methods. To tackle the problem, we formulate the general continuous influence maximization problem, investigate the essential properties, and develop a general coordinate descent algorithm as well as the engineering techniques for practical implementation. Our investigation remains general and does not assume any specific influence model. At the same time, we demonstrate that more efficient methods are feasible for specific influence models using the most popularly used independent influence model as a concrete example. Our extensive empirical study on four benchmark real world networks with synthesized purchase probability curves clearly illustrates that continuous influence maximization can improve influence spread significantly with very moderate extra running time comparing to the classical influence maximization methods.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Yu Yang"
      }, 
      {
        "name": "Xiangbo Mao"
      }, 
      {
        "name": "Jian Pei"
      }, 
      {
        "name": "Xiaofei He"
      }
    ], 
    "type": "Research", 
    "id": "432"
  }, 
  "991": {
    "title": "Cost-Effective Crowdsourced Entity Resolution: A Partial-Order Approach", 
    "abstract": "Crowdsourced entity resolution has recently attracted a significant attention because it can harness the wisdom of crowds to improve the quality of entity resolution. However existing techniques either cannot achieve perfect quality or incur huge monetary costs. To address these problems, we propose a cost-effective crowdsourced entity resolution framework, which can significantly reduce the monetary cost while keeping high quality. We first define a partial order on the pairs of records. Then we select a pair as a question and ask the crowd to check whether the records in the pair refer to the same entity.  After getting the answer of this pair, we infer the answers of other pairs based on the partial order.  Next we iteratively select pairs without answers to ask until all pairs have answers. We devise effective algorithms to judiciously select the pairs to ask in order to reduce the number of asked pairs. To further reduce the cost, we propose a grouping technique to group the pairs such that we only ask one pair instead of all pairs in each group. We develop error-tolerant techniques to tolerate the errors introduced by the partial order and the crowd. Experimental results show that our method reduces the cost to 1.25\\% of existing approaches (or existing approaches take more than 80 times money of our method) while not sacrificing the quality. ", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Chengliang Chai"
      }, 
      {
        "name": "Guoliang Li"
      }, 
      {
        "name": "Jian Li"
      }, 
      {
        "name": "Dong Deng"
      }, 
      {
        "name": "Jianhua Feng"
      }
    ], 
    "type": "Research,", 
    "id": "991"
  }, 
  "940": {
    "title": "DBSherlock: A Performance Diagnostic Tool for Transactional Databases", 
    "abstract": "Running an online transaction processing (OLTP) system is one of the most daunting tasks required of database administrators (DBAs). As businesses rely on OLTP databases to support their mission-critical and real-time applications, poor database performance directly impacts their revenue and user experience. As a result, DBAs constantly monitor, diagnose, and rectify any performance decays.  Unfortunately, the manual process of debugging and diagnosing OLTP performance problems is extremely tedious and non-trivial. Rather than being caused by a single slow query, performance problems in OLTP databases are often due to a large number of concurrent and competing transactions adding up to compounded, non-linear effects that are difficult to isolate. Sudden changes in request volume, transactional patterns, network traffic, or data distribution can cause previously abundant resources to become scarce, and the performance to plummet.  This paper presents a practical tool for assisting DBAs in quickly and reliably diagnosing performance problems in an OLTP database. By analyzing hundreds of statistics and configurations collected over the lifetime of the system, our algorithm quickly identifies a small set of potential causes and presents them to the DBA. The root-cause established by the DBA is  reincorporated into our algorithm as a new causal model to improve future diagnoses. Our experiments show that this algorithm is substantially more accurate than the state-of-the-art algorithm in finding correct explanations. ", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Dong Young Yoon"
      }, 
      {
        "name": "Ning Niu"
      }, 
      {
        "name": "Barzan Mozafari"
      }
    ], 
    "type": "Research,", 
    "id": "940"
  }, 
  "982": {
    "title": "Data Polygamy: The Many-Many Relationships among Urban Spatio-Temporal Data Sets", 
    "abstract": "The increasing ability to collect data from urban environments, coupled with a push towards openness by governments, has resulted in the availability of numerous spatio-temporal data sets covering diverse aspects of a city. Discovering relationships between these data sets can produce new insights by enabling domain experts to not only test but also generate hypotheses. However, discovering these relationships is difficult. First, a relationship between two data sets may occur only at certain locations and/or time periods. Second, the sheer number and size of the data sets, coupled with the diverse spatial and temporal scales at which the data is available, presents computational challenges on all fronts, from indexing and querying to analyzing them. Finally, it is non-trivial to differentiate between meaningful and spurious relationships. To address these challenges, we propose Data Polygamy, a scalable topology-based framework that allows users to query for statistically significant relationships between spatio-temporal data sets. We have performed an experimental evaluation using over 300 spatial-temporal urban data sets which shows that our approach is scalable and effective at identifying interesting relationships.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Fernando Chirigati"
      }, 
      {
        "name": "Harish Doraiswamy"
      }, 
      {
        "name": "Theodoros Damoulas"
      }, 
      {
        "name": "Juliana Freire"
      }
    ], 
    "type": "Research,", 
    "id": "982"
  }, 
  "Ind_101": {
    "title": "Data Processing at Facebook", 
    "abstract": "", 
    "subtype": "Industrial", 
    "authors": [
      {
        "name": "Guoqiang Jerry Chen"
      }, 
      {
        "name": "Janet L. Wiener"
      }, 
      {
        "name": "Shridhar Iyer"
      }, 
      {
        "name": "Anshul Jaiswal"
      }, 
      {
        "name": "Ran Lei Nikhil Simha"
      }, 
      {
        "name": "Wei Wang"
      }, 
      {
        "name": "Kevin Wilfong"
      }, 
      {
        "name": "Tim Williamson"
      }, 
      {
        "name": "Serhat Yilmaz"
      }
    ], 
    "type": "Industrial", 
    "id": "Ind_101"
  }, 
  "898": {
    "title": "Datometry Hyper-Q: Bridging the Gap Between Real Time and Historical Analytics", 
    "abstract": "Wall Street\u00d5s trading engines are complex database applications written for time series databases like kdb+ that uses the query language Q to perform real-time analysis. Extending the models to include other data sources, e.g., historic data, is critical for backtesting and compliance. However, Q applications cannot run directly on SQL databases. Therefore, financial institutions face the dilemma of either maintaining two separate application stacks, one written in Q and the other in SQL, which means increased IT cost and increased risk, or migrating all Q applications to SQL, which results in losing the inherent competitive advantage on Q real-time processing. Neither solution is desirable as both alternatives are costly, disruptive, and suboptimal.  In this paper we present Hyper-Q, a data virtualization platform that overcomes the chasm. Hyper-Q enables Q applications to run natively on PostgreSQL-compatible databases by translating queries and results on the fly. We outline the basic concepts, detail specific difficulties, and demonstrate the viability of the approach with a case study.", 
    "subtype": "Industrial", 
    "authors": [
      {
        "name": "Lyublena Antova"
      }, 
      {
        "name": "Rhonda Baldwin"
      }, 
      {
        "name": "Derrick Bryant"
      }, 
      {
        "name": "Tuan Cao"
      }, 
      {
        "name": "Michael Duller"
      }, 
      {
        "name": "John Eshleman"
      }, 
      {
        "name": "Zhongxian Gu"
      }, 
      {
        "name": "Entong Shen"
      }, 
      {
        "name": "Mohamed Soliman"
      }, 
      {
        "name": "F. Michael Waas"
      }
    ], 
    "type": "Industrial", 
    "id": "898"
  }, 
  "954": {
    "title": "Distributed Set Reachability", 
    "abstract": "In this paper, we focus on the efficient and scalable processing of set-reachability queries over a distributed, directed data graph. A {\\em set-reachability query} is a generalized form of a graph-reachability query, in which we consider two sets $S$ and $T$ of source and target vertices, respectively, to be given as the query. The result of a set-reachability query are all pairs of source and target vertices $(s, t)$, with $s \\in S$ and $t \\in S$, where $s$ is reachable to $t$ (denoted as $S \\leadsto T$). In case the data graph is partitioned into multiple, edge-disjoint subgraphs (e.g., when distributed across multiple compute nodes in a cluster), we refer to the resulting set-reachability problem as a {\\em distributed set-reachability query}. The key goal in processing a distributed set-reachability query over a partitioned data graph both efficiently and in a scalable manner is (1) to avoid redundant computations within the local compute nodes as much as possible, (2) to partially evaluate the local components of a reachability query $S \\leadsto T$ among all compute nodes in parallel, and (3) to minimize both the size and number of iteratively exchanged messages among the compute nodes.   The distributed set reachability problem has a plethora of applications in graph analytics and query-processing tasks. The current W3C recommendation for SPARQL 1.1, for example, introduces a notion of labeled {\\em property paths}, which resolves to processing a form of generalized graph-patterns queries with set-reachability predicates. Moreover, analyzing dependencies among {\\em social-network communities} inherently involves reachability checks between large sets of source and target vertices.Our experiments confirm very significant performance gains of our approach in comparison to state-of-art graph engines such as Giraph++, and over a variety of graph collections with up to one billion edges.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Sairam Gurajada"
      }, 
      {
        "name": "Martin  Theobald"
      }
    ], 
    "type": "Research,", 
    "id": "954"
  }, 
  "368": {
    "title": "Distributed Top-k Temporal Joins", 
    "abstract": "We study a particular kind of join, coined Ranked Temporal Join (RTJ), featuring predicates that compare time intervals and a scoring function associated with each predicate to quantify how well it is satisfied. RTJ queries are prevalent in a variety of applications such as network traffic monitoring, task scheduling, and tweet analysis. RTJ queries are often best interpreted as top-k queries where only the best matches are returned. We show how to exploit the nature of temporal predicates and the properties of their associated scoring semantics to design TKIJ, an efficient query evaluation approach on a distributed Map-Reduce architecture. TKIJ relies on an offline statistics computation that, given a time partitioning into granules, computes the distribution of intervals\u00d5 endpoints in each granule, and an online computation that generates query-dependent score bounds. Those statistics are used for workload assignment to reducers. This aims at reducing data replication, to limit I/O cost. Additionally, high-scoring results are distributed evenly to enable each reducer to prune unnecessary results. Our extensive experiments on synthetic and real datasets show that TKIJ outperforms state-of-the-art competitors and provides very good performance for n-ary RTJ queries on temporal data.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Julien Pilourdault"
      }, 
      {
        "name": "Sihem Amer-Yahia"
      }, 
      {
        "name": "Vincent Leroy"
      }
    ], 
    "type": "Research", 
    "id": "368"
  }, 
  "959": {
    "title": "Distributed Wavelet Thresholding for Maximum Error Metrics", 
    "abstract": "Modern data analytics involve simple and complex computations over enormous numbers of data records. The volume of data and the increasingly stringent response-time requirements place increasing emphasis on the efficiency of approximate query processing. A major challenge over the past years has been the efficient construction of fixed-space synopses that provide a deterministic quality guarantee, often expressed in terms of a maximum error metric. For data reduction, wavelet decomposition has proved to be a very effective tool, as it can successfully approximate sharp discontinuities and provide accurate answers to queries. However, existing polynomial time wavelet thresholding schemes that minimize maximum error metrics are constrained with impractical time and space complexities for large datasets. In order to provide a practical solution to the problem, we develop parallel algorithms that take advantage of key-properties of the wavelet decomposition and allocate tasks to multiple workers. To that end, we present i) a general framework for the parallelization of existing dynamic programming algorithms, ii) a parallel version of one such DP-based algorithm and iii) a new parallel greedy algorithm for the problem. To the best of our knowledge, this is the first attempt to scale algorithms for wavelet thresholding for maximum error metrics via a state-of-the-art distributed runtime. Our extensive experiments on both real and synthetic datasets over Hadoop show that the proposed algorithms achieve linear scalability and superior running-time performance compared to their centralized counterparts. Furthermore, our distributed greedy algorithm outperforms the distributed version of the current state-of-the-art dynamic programming algorithm by 2--4 times, while its performance gain does not compromise the quality of results.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "IOANNIS MYTILINIS"
      }, 
      {
        "name": "DIMITRIOS TSOUMAKOS"
      }, 
      {
        "name": "NECTARIOS KOZIRIS"
      }
    ], 
    "type": "Research,", 
    "id": "959"
  }, 
  "936": {
    "title": "Diversified Subgraph Querying in a Large Graph", 
    "abstract": "Subgraph querying in a large data graph is interesting for different applications. A recent study shows that top-k diversified results are useful since the number of matching subgraphs can be very large. In this work, we study the problem of top-k diversified subgraph querying which asks for a set of up to k subgraphs isomorphic to a given query graph, and which covers the most number of vertices. We propose a novel level-based algorithm for this problem which supports early termination and has a theoretical approximation guarantee. From experiments, most of our results on the tested real datasets are near optimal with a query time within 10ms on a commodity machine.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Yang Zhengwei"
      }, 
      {
        "name": "Ada Wai-Chee Fu"
      }, 
      {
        "name": "Ruifeng Liu"
      }
    ], 
    "type": "Research,", 
    "id": "936"
  }, 
  "929": {
    "title": "DualSim: Parallel Subgraph Enumeration in a Massive Graph on a Single Machine", 
    "abstract": "Subgraph enumeration is important for many applications such as subgraph frequencies, network motif discovery, graphlet kernel computation, and studying the evolution of social networks. Most earlier work on subgraph enumeration assumes that graphs are resident in memory, which encounters serious scalability problems. Recently, efforts to enumerate all subgraphs in a large-scale graph have seemed to enjoy some success by partitioning the data graph and exploiting the distributed frameworks such as MapReduce and distributed graph engines. However, we notice that all existing distributed approaches have serious performance problems for subgraph enumeration due to the explosive number of partial results. In this paper, we design and implement a disk-based, single machine parallel subgraph enumeration solution called DualSim that can handle massive graphs without maintaining exponential numbers of partial results. Specifically, we propose a novel concept of the dual approach for subgraph enumeration. The dual approach swaps the roles of the data graph and the query graph. Specifically, instead of fixing the matching order in the query and then matching data vertices, it fixes the data vertices by fixing a set of disk pages and then finds all subgraph matchings in these pages. This enables us to significantly reduce the number of disk reads. We conduct extensive experiments with various real-world graphs to systematically demonstrate the superiority of DualSim over state-of-the-art distributed subgraph enumeration methods. DualSim outperforms the state-of-the-art methods by up to orders of magnitude, while the state-of-the-art methods fail for many queries due to explosive intermediate results.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Hyeonji Kim"
      }, 
      {
        "name": "JuneYoung Lee"
      }, 
      {
        "name": "Sourav S Bhowmick"
      }, 
      {
        "name": "Wook-Shin Han"
      }, 
      {
        "name": "Jeong Hoon Lee"
      }, 
      {
        "name": "Seongyun Ko"
      }, 
      {
        "name": "Moath Jarrah"
      }
    ], 
    "type": "Research,", 
    "id": "929"
  }, 
  "378": {
    "title": "Dynamic Prefetching of Data Tiles for Interactive Visualization", 
    "abstract": "In this paper, we present ForeCache, a general-purpose tool for exploratory browsing of large datasets. ForeCache utilizes a client-server architecture, where the user interacts with a lightweight client-side interface to browse datasets, and the data to be browsed is retrieved from a DBMS running on a back-end server. We assume a detail-on-demand browsing paradigm, and optimize the back-end support for this paradigm by inserting a separate middleware layer in front of the DBMS. To improve response times, the middleware layer fetches data ahead of the user as she explores a dataset.  We consider two different mechanisms for prefetching: (a) learning what to fetch from the user\u00d5s recent movements, and (b) using data characteristics (e.g., histograms) to find data similar to what the user has viewed in the past. We incorporate these mechanisms into a single prediction engine that adjusts its prediction strategies over time, based on changes in the user\u00d5s behavior. We evaluated our prediction engine with a user study, and found that our dynamic prefetching strategy provides: (1) significant improvements in overall latency when compared with non-prefetching systems (430% improvement); and (2) substantial improvements in both prediction accuracy (25% improvement) and latency (88% improvement) relative to existing prefetching techniques.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Leilani Battle"
      }, 
      {
        "name": "Michael Stonebraker"
      }, 
      {
        "name": "Remco Chang"
      }
    ], 
    "type": "Research", 
    "id": "378"
  }, 
  "173": {
    "title": "ERMIA: Fast memory-optimized database system for heterogeneous workloads", 
    "abstract": "Large main memories and massively parallel processors have triggered not only a resurgence of high-performance memory- and multicore-optimized transaction processing systems, but also an increasing demand for processing heterogeneous workloads that include read-mostly transactions. Many modern transaction processing systems adopt a lightweight optimistic concurrency control (OCC) scheme to leverage its low overhead in low contention workloads. However,weobservethatthelightweightOCCisnotsuitable for heterogeneous workloads, causing signi\u00decant starvation of readmostly transactions and overall performance degradation. In this paper, we present ERMIA, a memory-optimized database system built from scratch to cater the need of handling heterogeneous workloads. ERMIA adopts snapshot isolation concurrency control to coordinate heterogeneous transactions and provides serializability when desired. Its physical layer supports the concurrency control schemes in a scalable way. Experimental results show that ERMIA delivers comparable or superior performance and nearlinear scalability in a variety of workloads, compared to a recent lightweight OCC-based system. At the same time, ERMIA maintains high throughput on read-mostly transactions when the performance of the OCC-based system drops by orders of magnitude. ", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Kangnyeon Kim"
      }, 
      {
        "name": "Tianzheng Wang"
      }, 
      {
        "name": "Ryan Johnson"
      }, 
      {
        "name": "Ippokratis Pandis"
      }
    ], 
    "type": "Research", 
    "id": "173"
  }, 
  "967": {
    "title": "Efficient Subgraph Matching by Postponing Cartesian Products", 
    "abstract": "In this paper, we study the problem of subgraph matching that extracts all subgraph isomorphic embeddings of a query graph $q$ in a large data graph $G$. The existing algorithms for subgraph matching follow Ullmann's backtracking approach; that is, iteratively map query vertices to data vertices by following a matching order of query vertices. It has been shown that the matching order of query vertices is a very important aspect to the efficiency of a subgraph  matching algorithm. Recently, many advanced techniques, such as enforcing connectivity and merging similar vertices in query or data graphs, have been proposed to provide an effective matching order with the aim to reduce unpromising intermediate results especially the ones caused by redundant Cartesian products. In this paper, for the first time we address the issue of unpromising results by Cartesian products from  ``dissimilar'' vertices. We propose a new framework by postponing the Cartesian products based on the structure of a query to minimize the redundant Cartesian products. Our second contribution is proposing a new path-based auxiliary data structure, with the size $O(|E(G)|\\times |V(q)|)$, to generate a matching order and conduct subgraph matching, which significantly reduces the exponential size $O(|V(G)|^{|V(q)|-1})$ of the existing path-based auxiliary data structure, where $V (G)$ and $E (G)$ are the vertex and edge sets of a data graph $G$, respectively, and $V (q)$ is the vertex set of a query $q$. Extensive empirical studies on real and synthetic graphs demonstrate that our techniques outperform the state-of-the-art algorithms by up to $3$ orders of magnitude.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Fei Bi"
      }, 
      {
        "name": "Lijun Chang"
      }, 
      {
        "name": "Xuemin Lin"
      }, 
      {
        "name": "Lu Qin"
      }, 
      {
        "name": "Wenjie Zhang"
      }
    ], 
    "type": "Research,", 
    "id": "967"
  }, 
  "937": {
    "title": "Efficient and Progressive Group Steiner Tree Search", 
    "abstract": "The Group Steiner Tree (GST) problem is a fundamental problem in database area that has been successfully applied to keyword search in relational databases and team search in social networks. The state-of-the-art algorithm for the GST problem is a parameterized dynamic programming (DP) algorithm, which finds the optimal tree in $O(3^kn+2^k(n\\log n + m))$ time, where $k$ is the number of given groups, $m$ and $n$ are the number of the edges and nodes of the graph respectively. The major limitations of the parameterized DP algorithm are twofold: (i) it is intractable even for very small values of $k$ (e.g., $k=8$) in large graphs due to its exponential complexity, and (ii) it cannot generate a solution until the algorithm has completed its entire execution. To overcome these limitations, we propose an efficient and progressive GST algorithm in this paper, called PrunedDP. It is based on newly-developed optimal-tree decomposition and conditional tree merging techniques. The proposed algorithm not only drastically reduces the search space of the parameterized DP algorithm, but it also produces progressively-refined feasible solutions during algorithm execution. To further speed up the PrunedDP algorithm, we propose a progressive $A^$-search algorithm, based on several carefully-designed lower-bounding techniques. We conduct extensive experiments to evaluate our algorithms on several large scale real-world graphs. The results show that our best algorithm is not only able to generate progressively-refined feasible solutions, but it also finds the optimal solution with at least two orders of magnitude acceleration over the state-of-the-art algorithm, using much less memory.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Rong-Hua LI"
      }, 
      {
        "name": "Lu Qin"
      }, 
      {
        "name": "Jeffrey Xu Yu"
      }, 
      {
        "name": "Rui Mao"
      }
    ], 
    "type": "Research,", 
    "id": "937"
  }, 
  "102": {
    "title": "Elastic Pipelining In an In-Memory Database Cluster", 
    "abstract": "An in-memory database cluster consists of multiple interconnected nodes with a large capacity of RAM and modern multi-core CPUs. As a conventional query processing strategy, pipelining remains a promising solution for in-memory parallel database systems, as it avoids expensive intermediate result materialization and parallelizes the data processing among nodes. However, to fully unleash the power of pipelining in a cluster with multi-core nodes, it is crucial for the query optimizer to generate good query plans with appropriate intra-node parallelism, in order to maximize CPU and network bandwidth utilization. A suboptimal plan, on the contrary, causes load imbalance in the pipelines and consequently degrades the query performance. Parallelism assignment optimization at compile time is nearly impossible, as the workload in each node is affected by numerous factors and is highly dynamic during query evaluation. To tackle this problem, we propose elastic pipelining, which makes it possible to optimize intra-node parallelism assignments in the pipelines based on the actual workload at runtime. It is achieved with the adoption of new elastic iterator model and a fully optimized dynamic scheduler. The elastic iterator model generally upgrades traditional iterator model with new dynamic multi-core execution adjustment capability. And the dynamic scheduler efficiently provisions CPU cores to query execution segments in the pipelines based on the light-weight measurements on the operators. Extensive experiments on real and synthetic (TPC-H) data show that our proposal achieves almost full CPU utilization on typical decision-making analytical queries, outperforming state-of-the-art open-source systems by a huge margin.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Li Wang"
      }, 
      {
        "name": "Zhou Minqi"
      }, 
      {
        "name": "Zhenjie Zhang"
      }, 
      {
        "name": "Yin Yang"
      }, 
      {
        "name": "Aoying Zhou"
      }
    ], 
    "type": "Research", 
    "id": "102"
  }, 
  "932": {
    "title": "Enabling Incremental Query Re-Optimization", 
    "abstract": "As declarative query processing techniques expand in scope --- to the Web, data streams, network routers, and cloud platforms --- there is an increasing need for \\emph{adaptive} query processing techniques that can re-plan in the presence of failures or unanticipated performance changes.  New information on data or the environment may affect which query plan we would prefer to run. Such adaptive techniques require innovation both in terms of the \\emph{algorithms used to estimate costs} (e.g., using control theory, alternative plans, filter ordering, probing using multi-armed bandit strategies) as well as in terms of the \\emph{planning algorithm} (i.e., redesigning the query optimizer to support continuous re-estimation of the best plan).  Existing cost-based query optimizers are not incremental in nature, and must be run ``from scratch'' upon each status or cost update.  Hence, they are not effective building blocks for rapid adaptivity.  An open question has been whether it is possible to build a \\emph{cost-based re-optimizer} for adaptive query processing in a streaming or repeated-query execution environment, e.g., by \\emph{incrementally} updating optimizer state given new cost information, much as a stream engine constantly updates its outputs given new data.  We show that this can be achieved beneficially, especially for stream processing workloads.  This lays the foundations upon which a variety of novel adaptive optimization \\emph{algorithms} can be built.  Our techniques build upon the recently proposed approach of formulating query plan enumeration as a set of \\emph{recursive datalog queries}; we develop a variety of novel optimization approaches to ensure effective pruning in both static and incremental cases. We implement our solution within an existing research query processing system, and show that it effectively supports cost-based initial optimization as well as frequent adaptivity. ", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Mengmeng Liu"
      }, 
      {
        "name": "Zachary Ives"
      }, 
      {
        "name": "Boon Loo"
      }
    ], 
    "type": "Research,", 
    "id": "932"
  }, 
  "364": {
    "title": "Estimating the Impact of Unknown Unknowns on Aggregate Query Results", 
    "abstract": "It is common practice for data scientists to acquire and integrate disparate data sources to achieve higher quality results. But even with a perfectly cleaned and merged data set, two fundamental questions remain: (1) is the integrated data set complete and (2) what is the impact of any unknown (i.e., unobserved) data on query results?  In this work, we develop and analyze techniques to estimate the impact of the unknown data (a.k.a., unknown unknowns) on simple aggregate queries. The key idea is that the overlap between different data sources enables us to estimate the number and values of the missing data items. Our main techniques are parameter-free and do not assume prior knowledge about the distribution. Through a series of experiments, we show that estimating the impact of unknown unknowns is invaluable to better assess the results of aggregate queries over integrated data sources. ", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Yeounoh Chung"
      }, 
      {
        "name": "Tim Kraska"
      }, 
      {
        "name": "Carsten Binnig"
      }, 
      {
        "name": "Michael Lind Mortensen"
      }
    ], 
    "type": "Research", 
    "id": "364"
  }, 
  "930": {
    "title": "Expressive Query Construction through Direct Manipulation of Nested Relational Results", 
    "abstract": "Despite extensive research on visual query systems, the standard way to interact with relational databases remains to be through SQL queries and tailored form interfaces. We consider three requirements to be essential to a successful alternative: (1)~query specification through direct manipulation of results, (2)~the ability to view and modify any part of the current query without departing from the direct manipulation interface, and (3)~SQL-like expressiveness. This paper presents the first visual query system to meet all three requirements in a single design. By directly manipulating nested relational results, and using spreadsheet idioms such as formulas and filters, the user can express a relationally complete set of query operators plus calculation, aggregation, outer joins, sorting, and nesting, while always remaining able to track and modify the state of the complete query. Our prototype gives the user an experience of responsive, incremental query building while pushing all actual query processing to the database layer. We evaluate our system with a formative and a controlled user study on 26 spreadsheet users; the controlled study shows our system significantly outperforming Microsoft Access on the System Usability Scale (SUS).", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Eirik Bakke"
      }, 
      {
        "name": "David Karger"
      }
    ], 
    "type": "Research,", 
    "id": "930"
  }, 
  "Ind_102": {
    "title": "Extracting Databases from Dark Data with DeepDive", 
    "abstract": "", 
    "subtype": "Industrial", 
    "authors": [
      {
        "name": "Ce Zhang"
      }, 
      {
        "name": "Jaeho Shin"
      }, 
      {
        "name": "Christopher Re"
      }, 
      {
        "name": "Michael Cafarella"
      }, 
      {
        "name": "Feng Niu"
      }
    ], 
    "type": "Industrial", 
    "id": "Ind_102"
  }, 
  "386": {
    "title": "Extracting Equivalent SQL From Imperative Code in Database Applications", 
    "abstract": "Optimizing the performance of database applications is an area of practical importance, and has received significant attention in recent years. In this paper we present an approach to this problem which is based on extracting a concise algebraic representation of (parts of) an application, which may include imperative code as well as SQL queries. The algebraic representation can then be translated into SQL to improve application performance by reducing the volume of data transferred, as well as reducing latency by minimizing the number of network round trips.  Our techniques can be used for performing optimizations of database applications that techniques proposed earlier cannot perform. The algebraic representations can also be used for other purposes such as extracting equivalent queries for keyword search on form results.  Our experiments indicate that the techniques we present are widely applicable to real world database applications, in terms of successfully extracting algebraic representations of application behavior, as well as in terms of providing performance benefits when used for optimization.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Venkatesh Emani"
      }, 
      {
        "name": "Karthik Ramachandra"
      }, 
      {
        "name": "S. Sudarshan"
      }, 
      {
        "name": "Subhro Bhattacharya"
      }
    ], 
    "type": "Research", 
    "id": "386"
  }, 
  "990": {
    "title": "FPTree: A Hybrid SCM-DRAM Persistent and Concurrent B-Tree for Storage Class Memory", 
    "abstract": "The advent of Storage Class Memory (SCM) is driving a rethink of storage systems towards a single-level architecture where memory and storage are merged. In this context, several works have investigated how to design persistent trees in SCM as a fundamental building block for these novel systems. However, these trees are significantly slower than \\dram-based counterparts since trees are latency-sensitive and SCM exhibits higher latencies than \\dram. In this paper we propose a novel hybrid SCM-DRAM persistent and concurrent B+-Tree, named Fingerprinting Persistent Tree (FPTree) that achieves similar performance to DRAM-based counterparts. In this novel design, leaf nodes are persisted in SCM while inner nodes are placed in DRAM and rebuilt upon recovery. The FPTree uses Fingerprinting, a technique that limits the expected number of in-leaf probed keys to one. In addition, we propose a hybrid concurrency scheme for the FPTree that is partially based on Hardware Transactional Memory. We conduct a thorough performance evaluation and show that the FPTree outperforms state-of-the-art persistent trees with different SCM latencies by up to a factor of 8.2. Moreover, we show that the FPTree scales very well on a machine with 88 logical cores. Finally, we integrate the evaluated trees in memcached and a prototype database. We show that the FPTree incurs an almost negligible performance overhead over using fully transient data structures, while significantly outperforming other persistent trees.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Ismail Oukid"
      }, 
      {
        "name": "Johan Lasperas"
      }, 
      {
        "name": "Anisoara Nica"
      }, 
      {
        "name": "Thomas Willhalm"
      }, 
      {
        "name": "Wolfgang Lehner"
      }
    ], 
    "type": "Research,", 
    "id": "990"
  }, 
  "925": {
    "title": "Fast Multi-column Sorting in Main-Memory Column-Stores", 
    "abstract": "Sorting is a crucial operation that could be used to implement SQL operators such as GROUP BY, ORDER BY, and SQL:2003 PARTITION BY. Queries with multiple attributes in those clauses are common in real workloads. When executing queries of that kind, state-of-the-art main-memory column-stores require one round of sorting per input column. With the advent of recent fast scans and denormalization techniques, that kind of multi-column sorting could become a bottleneck. In this paper, we propose a new technique called \u00d2code massaging\u00d3, which manipulates the bits across the columns so that the overall sorting time can be reduced by eliminating some rounds of sorting and/or by improving data parallelism. Empirical results show that a main-memory column-store with code massaging can achieve speedup of up to 4.7X, 4.7X, 2.8X, and 3.2X on TPC-H, TPC-H skew, TPC-DS, and real workload, respectively.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Wenjian Xu"
      }, 
      {
        "name": "ziqiang Feng"
      }, 
      {
        "name": "Eric Lo"
      }
    ], 
    "type": "Research,", 
    "id": "925"
  }, 
  "411": {
    "title": "FluxQuery: An Execution Framework for Highly Interactive Query Workloads", 
    "abstract": "Modern computing devices and user interfaces have necessitated highly interactive querying. Some of these interfaces issue a large number of dynamically changing and continuous queries to the backend. In others, users expect to inspect results during the query formulation process, in order to guide or help them towards specifying a full-fledged query. Thus, users end up issuing a fast-changing workload to the underlying database. In such situations, user's query intent can be thought of as being in flux.   In this paper, we show that the traditional query execution engines are not well-suited for this new class of highly interactive workloads. We propose a novel model to interpret the variability of likely queries in a workload. We implemented a cyclic scan-based approach to process queries from such workloads in an efficient and practical manner while reducing the overall system load. We evaluate and compare our methods with traditional systems and demonstrate the scalability of our approach, enabling thousands of queries to run simultaneously within interactive response times given low memory and CPU requirements.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Roee Ebenstein"
      }, 
      {
        "name": "Niranjan Kamat"
      }, 
      {
        "name": "Arnab Nandi"
      }
    ], 
    "type": "Research", 
    "id": "411"
  }, 
  "962": {
    "title": "Functional Dependencies for Graphs", 
    "abstract": "We propose a class of functional dependencies for graphs, referred to as GFDs. GFDs capture both attribute-value dependencies and topological structures of entities, and subsume conditional functional dependencies (CFDs) as a special case. We show that the satisfiability and implication problems for GFDs are coNP-complete and NP-complete, respectively, no worse than their CFD counterparts. We also show that the validation problem for GFDs is coNP-complete. Despite the intractability, we develop parallel scalable algorithms for catching violations of GFDs in large-scale graphs. Using real-life and synthetic data, we experimentally verify that \\GFDs provide an effective approach to detecting inconsistencies in knowledge and social graphs. ", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Wenfei Fan"
      }, 
      {
        "name": "YINGHUI WU"
      }, 
      {
        "name": "Jingbo Xu"
      }
    ], 
    "type": "Research,", 
    "id": "962"
  }, 
  "950": {
    "title": "GPL: A GPU-based Pipelined Query Processing Engine", 
    "abstract": "Graphics Processing Units (GPUs) have evolved as a powerful query co-processor for main memory On-Line Analytical Processing (OLAP) databases. However, existing GPU-based query processors adopt a kernel-based execution approach which optimizes individual kernels for resource utilization and executes the GPU kernels involved in the query plan one by one. Such a kernel-based approach cannot utilize all GPU resources efficiently due to the resource underutilization of individual kernels and excessive memory accesses across kernel executions. In this paper, we propose GPL, a novel pipelined query execution engine to improve the resource utilization of query co-processing on the GPU. Different from the existing kernel-based execution, GPL takes advantage of hardware features of new-generation GPUs including concurrent kernel execution and efficient data communication channel between kernels. We use the tiling technique to logically partition the input data into smaller data tiles so that the pipelined query plan can be adapted in a cost-based manner. We further develop an analytical model to guide the generation of the optimal pipelined query plan. We evaluate GPL with TPC-H queries on both AMD and NVIDIA GPUs. The experimental results show that 1) the analytical model is able to guide determining the suitable parameter values in pipelined query execution plan, and 2) GPL is able to significantly outperform the state-of-the-art kernel-based query processing approaches, with improvement by 41% and 50% on AMD and NVIDIA GPUs, respectively.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Jiong He"
      }, 
      {
        "name": "Paul Johns"
      }, 
      {
        "name": "Bingsheng He"
      }
    ], 
    "type": "Research,", 
    "id": "950"
  }, 
  "924": {
    "title": "GTS: A Fast and Scalable Graph Processing Method based on Streaming Topology to GPUs", 
    "abstract": "A fast and scalable graph processing method becomes increasingly important as graphs become popular in a wide range of applications and their sizes are growing rapidly. Most of distributed graph processing methods require a lot of machines equipped with a total of thousands of GPU cores and a few terabyte main memory for handling billion-scale graphs. Meanwhile, GPUs could be a promising direction toward fast processing of large-scale graphs by exploiting thousands of GPU cores. All of the existing methods using GPUs, however, fail to process large-scale graphs that do not fit in main memory of a single machine. Here, we propose a fast and scalable graph processing method \\GS\\ that handles even RMAT32\\,(64 billion edges) very efficiently only by using a single machine. The proposed method stores graphs in PCI-E SSDs and executes a graph algorithm using thousands of GPU cores while streaming topology data of graphs to GPUs via PCI-E interface. \\GS\\ is fast due to no communication overhead and scalable due to no data duplication from graph partitioning among machines. Through extensive experiments, we show that \\GS\\ consistently and significantly outperforms the major distributed graph processing methods, GraphX, Giraph, and PowerGraph, and the state-of-the-art GPU-based method TOTEM.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Min-Soo Kim"
      }, 
      {
        "name": "Kyu-Hyeon An"
      }, 
      {
        "name": "Himchan Park"
      }, 
      {
        "name": "Hyunseok Seo"
      }, 
      {
        "name": "Jinwook Kim"
      }
    ], 
    "type": "Research,", 
    "id": "924"
  }, 
  "943": {
    "title": "GeckoFTL: Scalable Flash Translation Techniques For Very Large Flash Devices", 
    "abstract": "The amount of metadata needed for a flash translation layer is proportional to the storage capacity of a flash device. Ideally, this metadata should be stored in integrated RAM to enable fast access. However, as flash devices scale to terabytes, the space requirements of state-of-the-art flash translation layers (FTLs) are exceeding the available integrated RAM. Moreover, recovery time after power failure, which is proportional to the size of the metadata, is becoming impractical.   In this paper, we identify a key component of the metadata called the Page Validity Bitmap (PVB) as the bottleneck. PVB is used by the garbage-collectors of state-of-the-art FTLs to keep track of which physical pages in the device are invalid. PVB constitutes 95% of the FTL\u00d5s overall metadata space requirement, and recreating it when power fails takes most of recovery time. To solve this problem, we propose a novel page-associative FTL called GeckoFTL, whose central innovation is replacing PVB with a new data structure called Logarithmic Gecko. Logarithmic Gecko is similar to LSM-trees in that it logs updates about page validity metadata and to later reorganize them in flash to ensure fast and scalable access time. Relative to the baseline of storing PVB in flash, Logarithmic Gecko enables cheaper updates at the cost of slightly more expensive garbage-collection queries. We show that this is a good trade-off because (1) updates are intrinsically more frequent than garbage-collection queries to page validity metadata, and (2) flash writes are more expensive than flash reads. We demonstrate analytically and empirically that GeckoFTL achieves a 95% reduction in space requirements and a 51% reduction in recovery time by storing page validity metadata in flash while keeping the contribution to internal IO overheads 98% lower than the baseline. ", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Niv Dayan"
      }, 
      {
        "name": "Philippe Bonnet"
      }, 
      {
        "name": "Stratos Idreos"
      }
    ], 
    "type": "Research,", 
    "id": "943"
  }, 
  "946": {
    "title": "Generating Preview Tables for Entity Graphs", 
    "abstract": "We witness an unprecedented proliferation of big, complex entity graphs that capture many types of entities and their relationships. Users are tapping into big, complex entity graphs for many applications. It is challenging to select entity graphs for a particular need, given abundant datasets from many sources and the oftentimes scarce information for them.  We propose methods to produce preview tables for compact presentation of important entity types and relationships in entity graphs. The preview tables assist users in attaining a quick and rough preview of the data.  They can be shown in a limited display space for a user to browse and explore, before she decides to spend time and resources to fetch and investigate the complete dataset. We propose scoring functions for measuring the goodness of previews. Based on the scoring measures, We formulate several optimization problems that look for previews with the highest scores according to intuitive goodness measures, under various constraints on preview size and distance between preview tables. The optimization problem under distance constraint is NP-hard.  We design a dynamic-programming algorithm and an Apriori-style algorithm for finding optimal previews. Our experiments, comparison with related work and user studies demonstrated the scoring measures' accuracy and the discovery algorithms' efficiency.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Ning Yan"
      }, 
      {
        "name": "Sona Hasani"
      }, 
      {
        "name": "Abolfazl Asudeh"
      }, 
      {
        "name": "Chengkai Li"
      }
    ], 
    "type": "Research,", 
    "id": "946"
  }, 
  "873": {
    "title": "Goods: Organizing Google's Datasets", 
    "abstract": "Enterprises increasingly rely on structured datasets to run their businesses. These datasets take a variety of forms, such as structured files, databases, spreadsheets, or even services that provide access to the data.  The datasets often reside in different storage systems, may vary in their formats, may change every day.  In this paper, we present \\goods, a project to rethink how we organize structured datasets at scale, in a setting where teams use diverse and often idiosyncratic ways to produce the datasets and where there is no centralized system for storing and querying them.  \\goods\\ extracts metadata ranging from salient information about each dataset (owners, timestamps, schema) to relationships among datasets, such as similarity and provenance.  It then exposes this metadata through services that allow engineers to find datasets within the company, to monitor datasets, to annotate them in order to enable others to use their datasets, and to analyze relationships between them.  We discuss the technical challenges that we had to overcome in order to crawl and infer the metadata for billions of datasets, to maintain the consistency of our metadata catalog at scale, and to expose the metadata to users. We believe that many of the lessons that we learned are applicable to building large-scale enterprise-level data-management systems in general.", 
    "subtype": "Industrial", 
    "authors": [
      {
        "name": "Sudip Roy"
      }, 
      {
        "name": "Neoklis Polyzotis"
      }, 
      {
        "name": "Natasha Noy"
      }, 
      {
        "name": "Steven Whang"
      }, 
      {
        "name": "Christopher Olston"
      }, 
      {
        "name": "Alon Halevy"
      }, 
      {
        "name": "Flip Korn"
      }
    ], 
    "type": "Industrial", 
    "id": "873"
  }, 
  "970": {
    "title": "Graph Analytics Through Fine-Grained Parallelism", 
    "abstract": "Large graphs are getting increasingly popular and even indispensable in many applications, for example, in social media data, large networks, and knowledge bases. Efficient graph analytics thus becomes an important subject of study. To increase efficiency and scalability, in-memory computation and parallelism have been explored extensively to speed up various graph analytical workloads. In many graph analytical engines (e.g., Pregel, Neo4j, GraphLab), parallelism is achieved via one of the three concurrency control models, namely, bulk synchronization processing (BSP), asynchronous processing, and synchronous processing. Among them, synchronous processing has the potential to achieve the best performance due to fine-grained parallelism, while ensuring the correctness and the convergence of the computation, if an effective concurrency control scheme is used. This paper explores the topological properties of the underlying graph to design and implement a highly effective concurrency control scheme for efficient synchronous processing in an in-memory graph analytical engine. Our design uses a novel hybrid approach that combines 2PL (two-phase locking) with OCC (optimistic concurrency control), for high degree and low degree vertices in a graph respectively. Our results show that the proposed hybrid synchronous scheduler has significantly outperformed other synchronous schedulers in existing graph analytical engines, as well as BSP and asynchronous schedulers.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Zechao Shang"
      }, 
      {
        "name": "Feifei Li"
      }, 
      {
        "name": "Jeffrey Xu Yu"
      }, 
      {
        "name": "Zhiwei Zhang"
      }, 
      {
        "name": "Hong Cheng"
      }
    ], 
    "type": "Research,", 
    "id": "970"
  }, 
  "394": {
    "title": "Graph Indexing for Shortest-Path Finding over Dynamic Sub-Graphs", 
    "abstract": "A variety of applications spanning various domains, e.g., social networks, transportation, and bioinformatics, have graphs as first-class citizens. These applications share a vital operation, namely, finding the shortest path between two nodes. In many scenarios, users are interested in filtering the graph before finding the shortest path. For example, in social networks, one may need to compute the shortest path between two persons on a sub-graph containing only family relationships. This paper focuses on dynamic graphs with labeled edges, where the target is to find a shortest path after filtering some edges based on user-specified query labels. This problem is termed the Edge-Constrained Shortest Path query (or ECSP, for short). This paper introduces Edge-Disjoint Partitioning (EDP, for short), a new technique for efficiently answering ECSP queries over dynamic graphs. EDP has two main components: a dynamic index that is based on graph partitioning, and a traversal algorithm that exploits the regular patterns of the answers of ECSP queries. The main idea of EDP is to partition the graph based on the labels of the edges. On demand, EDP computes specific sub-paths within each partition and updates its index. The computed sub-paths act as pre-computations that can be leveraged by future queries. To answer an ECSP query, EDP connects sub-paths from different partitions using its efficient traversal algorithm. EDP can dynamically handle various types of graph updates, e.g., label, edge, and node updates. The index entries that are potentially affected by graph updates are invalidated and re-computed on demand. EDP is evaluated using real graph datasets from various domains. Experimental results demonstrate that EDP can achieve query performance gains of up to four orders of magnitude in comparison to state of the art techniques.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Mohamed Hassan"
      }, 
      {
        "name": "Walid Aref"
      }, 
      {
        "name": "Ahmed Aly"
      }
    ], 
    "type": "Research", 
    "id": "394"
  }, 
  "949": {
    "title": "Graph Stream Summarization: From Big Bang to Big Crunch", 
    "abstract": "A graph stream, which refers to the graph with edges being updated sequentially in a form of a stream, has important applications in cyber security and social networks. Due to the sheer volume and highly dynamic nature of graph streams, the practical way of handling them is by summarization. Given a graph stream G, directed or undirected, the problem of graph stream summarization is to summarize G as SG with a much smaller (sublinear) space, linear construction time and constant maintenance cost for each edge update, such that SG allows many queries over G to be approximately conducted efficiently. The widely used practice of summarizing data streams is to treat each stream element independently by e.g., hashing- or sampling-based methods, without maintaining the connections between elements. Hence, existing methods can only solve ad-hoc problems, without supporting diversified and complicated analytics over graph streams. We present B3C, a generalized graph stream summary. Given an incoming edge, it summarizes both node and edge information in constant time. Consequently, the summary forms a graphical sketch where edges capture the connections inside elements, and nodes maintain relationships across elements. We discuss a wide range of supported queries and establish some error bounds. In addition, we experimentally show that B3C can effectively and efficiently support analytics over graph streams.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Nan Tang"
      }, 
      {
        "name": "Qing Chen"
      }, 
      {
        "name": "Prasenjit Mitra"
      }
    ], 
    "type": "Research,", 
    "id": "949"
  }, 
  "Ind_103": {
    "title": "Have Your Data and Query It Too: From Key-Value Caching to Big Data Management", 
    "abstract": "", 
    "subtype": "Industrial", 
    "authors": [
      {
        "name": "Dipti Borkar"
      }, 
      {
        "name": "Ravi Mayurum"
      }, 
      {
        "name": "Gerald Sangudi"
      }, 
      {
        "name": "Michael Carey"
      }
    ], 
    "type": "Industrial", 
    "id": "Ind_103"
  }, 
  "390": {
    "title": "Holistic Influence Maximization: Combining Scalability and Efficiency with Opinion-Aware Models", 
    "abstract": "The steady growth of graph data from social networks has resulted in wide-spread research in finding solutions to the influence maximization problem. In this paper, we propose a holistic solution to the influence maximization (IM) problem. (1) We introduce an opinion-cum-interaction (OI) model that closely mirrors the real-world scenarios. Under the OI model, we introduce a novel problem of Maximizing the Effective Opinion (MEO) of influenced users. We prove that the MEO problem is NP-hard and cannot be approximated within any finite ratio unless P=NP. (2) We propose a heuristic algorithm OSIM to efficiently solve the MEO problem. To better explain the OSIM heuristic, we first introduce EaSyIM \u00d0 the opinion-oblivious version of OSIM, a scalable algorithm capable of running within practical compute times on commodity hardware. In addition to serving as a fundamental building block for OSIM, EaSyIM is capable of addressing the scalability aspect \u00d0 memory consumption and running time, of the IM problem as well.  Empirically, our algorithms are capable of maintaining the deviation in the spread always within 5% of the best known methods in the literature. In addition, our experiments show that both OSIM and EaSyIM are effective, efficient, scalable and significantly enhance the ability to analyze real datasets.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Sainyam Galhotra"
      }, 
      {
        "name": "Akhil Arora"
      }, 
      {
        "name": "Shourya Roy"
      }
    ], 
    "type": "Research", 
    "id": "390"
  }, 
  "977": {
    "title": "How to Architect a Query Compiler", 
    "abstract": "This paper studies architecting query compilers. The state of the art in query compiler construction is lagging behind that in the compilers field. We attempt to remedy this by exploring the key causes of technical challenges in need of well founded solutions, and by gathering the most relevant ideas and approaches from the PL and compilers communities for easy digestion by database researchers. All query compilers known to us are more or less monolithic template expanders that do the bulk of the compilation task in one large leap. Such systems are hard to build and maintain. We propose to use a stack of multiple DSLs on different levels of abstraction with lowering in multiple steps to make query compilers easier to build and extend, ultimately allowing us to create more convincing and sustainable compiler-based data management systems. We attempt to derive our advice for creating such DSL stacks from widely acceptable principles. We have also re-created a well-known query compiler following these ideas and report on this effort.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Amir Shaikhha"
      }, 
      {
        "name": "Yannis Klonatos"
      }, 
      {
        "name": "lionel Parreaux"
      }, 
      {
        "name": "Lewis Brown"
      }, 
      {
        "name": "Mohammad Dashti"
      }, 
      {
        "name": "Christoph Koch"
      }
    ], 
    "type": "Research,", 
    "id": "977"
  }, 
  "984": {
    "title": "How to win a hot dog eating contest", 
    "abstract": "In the quest for valuable information, modern big data applications continuously monitor streams of data. These applications demand low latency stream processing even when faced with high volume and velocity of incoming changes and the user's desire to ask complex queries. In this paper, we study low-latency incremental computation of complex SQL queries in both local and distributed streaming environments. We develop a technique for the efficient incrementalization of queries with nested aggregates for batch updates. We identify the cases in which batch processing can boost the performance of incremental view maintenance but also demonstrate that tuple-at-a-time processing often can achieve better performance in local mode. Batch updates are essential for enabling distributed incremental view maintenance and amortizing the cost of network communication and synchronization. We show how to derive incremental programs optimized for running on large-scale processing platforms. Our implementation of distributed incremental view maintenance can process tens of million of tuples with few-second latency on a scale of up to 1,000 nodes. ", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Milos Nikolic"
      }, 
      {
        "name": "Christoph Koch"
      }, 
      {
        "name": "Mohammad Dashti"
      }
    ], 
    "type": "Research,", 
    "id": "984"
  }, 
  "885": {
    "title": "Hybrid Garbage Collection for Multi-Version Concurrency Control in SAP HANA", 
    "abstract": "While multi-version concurrency control (MVCC) supports fast and robust performance in in-memory, relational databases, it has the potential problem of a growing number of versions over time due to obsolete versions. Although a few TB of main memory is available for enterprise machines, the memory resource should be used carefully for economic and practical reasons. Thus, in order to maintain the necessary number of versions in MVCC, versions which will no longer be used need to be deleted. This process is called garbage collection. MVCC uses the concept of \\emph{visibility} to define garbage. A set of versions for each record is first identified as candidate if their version timestamps are lower than the minimum value of snapshot timestamps of active snapshots in the system. All such candidates, except the one which has the maximum version timestamp, are safely reclaimed as garbage versions. In mixed  OLTP and OLAP workloads, the typical garbage collector may not effectively reclaim record versions. In these workloads, OLTP applications generate a high volume of new versions, while long-lived queries or transactions in OLAP applications often block garbage collection, since we need to compare the version timestamp of each record version with the snapshot timestamp of the oldest, long-lived snapshot. Thus, these workloads typically cause the in-memory version space to grow. Additionally,  the increasing version chains of records over time may also increase the traversal cost for them.  In this paper, we present an efficient and effective garbage collector called {\\HybridGC} in SAP HANA.  HybridGC integrates three novel concepts of garbage collection: timestamp-based group garbage collection, table garbage collection, and interval garbage collection.  Through experiments using mixed OLTP and OLAP workloads, we show that {\\HybridGC} effectively and efficiently collects garbage versions with negligible overhead.", 
    "subtype": "Industrial", 
    "authors": [
      {
        "name": "Juchang Lee"
      }, 
      {
        "name": "Hyungyu Shin"
      }, 
      {
        "name": "Chang Gyoo Park"
      }, 
      {
        "name": "Seongyun Ko"
      }, 
      {
        "name": "Yongjae Chuh"
      }, 
      {
        "name": "Jaeyun Noh"
      }, 
      {
        "name": "Wolfgang Stephan"
      }, 
      {
        "name": "Wook-Shin Han"
      }
    ], 
    "type": "Industrial", 
    "id": "885"
  }, 
  "401": {
    "title": "Hybrid Pulling/Pushing for I/O-Efficient Distributed and Iterative Graph Computing", 
    "abstract": "Billion-node graphs are rapidly growing in size in many applications such as online social networks. Most graph algorithms generate a large number of messages during iterative computations. Vertex-centric distributed systems usually store graph data and message data on disk to improve scalability. Currently, distributed systems with disk-resident data take a push-based approach to handle messages. This works well if few messages reside on disk. Otherwise, it is I/O-inefficient due to expensive random writes. The existing memory-resident pull-based approach individually pulls messages for each vertex on demand. In disk scenarios, although this avoids disk operations of messages, expensive I/O costs are incurred by random and frequent access to vertices.  This paper proposes a hybrid solution to support switching between push and pull adaptively, to obtain optimal performance for distributed systems with disk-resident data in different scenarios. We first employ a block-centric technique (b-pull) to improve the I/O-performance of pulling messages, although the iterative computation is vertex-centric. I/O costs of data accesses are shifted from the receiver side where messages are written/read by push to the sender side where graph data are read by b-pull. Graph data are organized by clustering vertices and edges to achieve high I/O-efficiency. Second, we design a seamless switching mechanism and a prominent performance prediction method to guarantee efficiency when switching between push and b-pull. We conduct extensive performance studies to confirm the effectiveness of our proposals over existing up-to-date solutions using a broad spectrum of real-world graphs.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Zhigang Wang"
      }, 
      {
        "name": "Yu Gu"
      }, 
      {
        "name": "Yubin Bao"
      }, 
      {
        "name": "Ge Yu"
      }, 
      {
        "name": "Jeffrey Xu Yu"
      }
    ], 
    "type": "Research", 
    "id": "401"
  }, 
  "975": {
    "title": "Interactive and Deterministic Data Cleaning", 
    "abstract": "We present Falcon, an interactive, deterministic, and declarative data cleaning system, which uses SQL update (SQLU) queries as the language to repair data. Falcon does not rely on the existence of a set of pre-defined data quality rules. On the contrary, it encourages users to explore the data, identify possible problems, and make updates to fix them. Bootstrapped by one user update, Falcon guesses a set of possible sql update queries that can be used to repair the data. The main technical challenge addressed in this paper consists in finding a set of sql update queries that is minimal in size and at the same time fixes the largest number of errors in the data. We formalize this problem as a search in a lattice-shaped space. To guarantee that the chosen updates are semantically correct, Falcon navigates the lattice by interacting with users to gradually validate the set of sql update queries. Besides using traditional one-hop based traverse algorithms (e.g., BFS or DFS), we describe novel multi-hop search algorithms such that Falcon can dive over the lattice and conduct the search efficiently. Our novel search strategy is coupled with a number of optimization techniques to further prune the search space and efficiently maintain the lattice. We have conducted extensive experiments using both real-world and synthetic datasets to show that Falcon can effectively communicate with users in data repairing.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Jian He"
      }, 
      {
        "name": "Enzo Veltri"
      }, 
      {
        "name": "Donatello Santoro"
      }, 
      {
        "name": "Guoliang Li"
      }, 
      {
        "name": "Gianni Mecca"
      }, 
      {
        "name": "Paolo Papotti"
      }, 
      {
        "name": "Nan Tang"
      }
    ], 
    "type": "Research,", 
    "id": "975"
  }, 
  "404": {
    "title": "Lazily Approximating Complex AdHoc Queries in Big Data Clusters", 
    "abstract": "Experience with queries in a large production big data cluster reveals that apriori samples are untenable. Accesses to input files are heavy tailed. And, queries often join multiple inputs or have complex filters. Consequently, systems like BlinkDB which store differently stratified samples of the inputs have small coverage and limited performance gains even when offered several times the size of the inputs to store samples.   This paper explores lazy on-the-fly sampling. We assume no pre-existing samples, indices, materialized views or foreknowledge of the queries.   When a query arrives, our system carefully injects sampler operators into the query execution graph. Even though all the input data has to be read at least once, the gains from such on-the-fly sampling can be substantial because big data queries typically perform many passes over the input-- a general join has 2-to-3 reads and 1 network shuffle.   In addition, key new techniques include: (1) a new sampling operator that effectively mimics sampling of the join output by sampling the inputs of the join instead and (2) a new query optimizer that automatically inserts appropriate samplers at appropriate locations in the query graph. Our system uses three different samplers all of which function in a \"streaming\" mode, ie, in one pass over data, with sub-linear memory footprint and in a partitionable manner. We offer transformation rules that carefully move these samplers ever closer to the raw inputs where they have higher perf gains while ensuring that the err remains in check. An implementation on a cluster with O(10^4) machines shows that up to 60\\% of the queries in the TPC-DS benchmark speed-up by a median of 2X with negligible error, both of which are substantially higher than BlinkDB. ", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Srikanth Kandula"
      }, 
      {
        "name": "Anil Shanbhag"
      }, 
      {
        "name": "Aleksandar Vitorovic"
      }, 
      {
        "name": "Matt Olma"
      }, 
      {
        "name": "Robert Grandl"
      }, 
      {
        "name": "Surajit Chaudhuri"
      }, 
      {
        "name": "Bolin Ding"
      }
    ], 
    "type": "Research", 
    "id": "404"
  }, 
  "391": {
    "title": "LazyLSH: Approximate Nearest Neighbor Search for Multiple Distance Functions with a Single Index", 
    "abstract": "Due to the ``curse of dimensionality\" problem, it is very expensive to process the nearest neighbor (NN) query in high-dimensional spaces; and hence, approximate approaches, such as Locality-Sensitive Hashing (LSH), are widely used for their theoretical guarantees and empirical performance. Current LSH-based approaches target at the L1 and L2 spaces, while as shown in previous work, the fractional distance metrics (Lp metrics with 0 < p < 1) can provide more insightful results than the usual L1 and L2 metrics for data mining and multimedia applications. However, none of the existing work can support multiple fractional distance metrics using one index. In this paper, we propose LazyLSH that answers approximate nearest neighbor queries for multiple Lp metrics with theoretical guarantees. Different from previous LSH approaches which need to build one dedicated index for every query space, LazyLSH uses a single base index to support the computations in multiple Lp spaces, significantly reducing the maintenance overhead. Extensive experiments show that LazyLSH provides more accurate results for approximate kNN search under fractional distance metrics.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Yuxin Zheng"
      }, 
      {
        "name": "Qi Guo"
      }, 
      {
        "name": "Anthony Tung"
      }, 
      {
        "name": "Sai Wu"
      }
    ], 
    "type": "Research", 
    "id": "391"
  }, 
  "402": {
    "title": "Learning Linear Regression Models over Factorized Joins", 
    "abstract": "  We investigate the problem of building least squares regression   models over training datasets defined by arbitrary join queries on   database tables. Our key observation is that joins entail a high   degree of redundancy in both computation and data representation,   which is not required for the end-to-end solution to learning over   joins.    We propose a variant of batch gradient descent called F that   can learn the parameters of a linear regression function in two   passes over factorized representations of the datasets, even though   they can be exponentially smaller than the flat relational datasets.   We consider factorizations of asymptotically optimal sizes, which   are governed by well-understood properties of the hypergraph of the   join query Q.     F exploits the factorization structure, a rewriting of the   regression objective function that decouples the computation of   cofactors of model parameters from their convergence, and the   commutativity of cofactor computation with relational union and   projection. The join intermixed with F's cofactor computation   is expressible as one SQL query.    In experiments with real-world and synthetic datasets, F    outperforms the state-of-the-art systems R, Python StatsModels,    and MADlib, by up to three orders of magnitude. ", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Dan Olteanu"
      }, 
      {
        "name": "Maximilian Schleich"
      }, 
      {
        "name": "Radu Ciucanu"
      }
    ], 
    "type": "Research", 
    "id": "402"
  }, 
  "309": {
    "title": "Learning-Aided Cleansing for Indoor RFID Data", 
    "abstract": "RFID is widely used for object tracking in indoor environments, e.g., airport baggage tracking. Analyzing RFID data generated in such scenarios offers insight into the underlying tracking systems and enables prediction of system behaviors. However, the uncertain characteristics of RFID data, including noises (cross readings) and incompleteness (missing readings), pose challenges to high level RFID data querying and analysis. In this paper, we address such challenges by a learning-aided data cleansing approach that requires no detailed prior knowledge about the spatio-temporal properties of the indoor space and the RFID reader deployment. Requiring minimal information about RFID deployment, the approach learns relevant knowledge from raw RFID data and uses it to cleanse the data. In particular, we model raw RFID readings as time series that are quite sparse because the indoor space is only partly covered by a limited number of RFID readers. Essentially, we use an Indoor RFID Multi-variate Hidden Markov Model (IR-MHMM) to capture the uncertainties of indoor RFID data as well as the correlation of moving object locations and object's RFID reading. We propose for IR-MHMM three state space design methods that enable the learning of parameters while contending with raw RFID data time series. We solely use raw uncleaned RFID data for the learning of model parameters, and no special labeled data or ground truth data is required. The resulting IR-MHMM aided RFID data cleansing approach is able to recover missing readings and reduce cross readings with high effectiveness and efficiency, as demonstrated by the extensive experimental studies with both synthetic and real data. With sufficient indoor RFID data for learning, the proposed approach achieves data cleansing accuracy that is comparable to and even better than state-of-the-art techniques requiring very detailed prior knowledge, making our solution superior in terms of both effectiveness and employability.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Asif iqbal Baba"
      }, 
      {
        "name": "Manfred Jaeger"
      }, 
      {
        "name": "Hua Lu"
      }, 
      {
        "name": "Torben Bach Pedersen"
      }, 
      {
        "name": "Wei-Shinn Ku"
      }, 
      {
        "name": "Xike Xie"
      }
    ], 
    "type": "Research", 
    "id": "309"
  }, 
  "931": {
    "title": "Local Similarity Search for Unstructured Text", 
    "abstract": "With the growing popularity of electronic documents, replication can occur for many reasons. People may copy text segments from various sources and make modifications. In this paper, we study the problem of local similarity search to find partially replicated text. Unlike existing studies on similarity search which find entirely duplicated documents, our target is to identify documents that approximately share a pair of sliding windows which differ by no more than $\\tau$ tokens. Our problem is technically challenging because for sliding windows the tokens to be indexed are less selective than entire documents, rendering set similarity join-based algorithms less efficient. Our proposed method is based on enumerating token combinations to obtain signatures with high selectivity. In order to strike a balance between signature and candidate generation, we partition the token universe and for different partitions we generate combinations composed of different numbers of tokens. A cost-aware algorithm is devised to find a good partitioning of the token universe. We also propose to leverage the overlap between adjacent windows to share computation and thus speed up query processing. In addition, we develop the techniques to support the large thresholds. Experiments on real datasets demonstrate the efficiency of our method against alternative solutions.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Pei Wang"
      }, 
      {
        "name": "Chuan Xiao"
      }, 
      {
        "name": "Jianbin Qin"
      }, 
      {
        "name": "Wei Wang"
      }, 
      {
        "name": "Xiaoyang Zhang"
      }, 
      {
        "name": "Yoshiharu Ishikawa"
      }
    ], 
    "type": "Research,", 
    "id": "931"
  }, 
  "839": {
    "title": "Low-Overhead Asynchronous Checkpointing in Main-Memory Database Systems", 
    "abstract": "As it becomes increasingly common for transaction processing systems to operate on datasets that fit within the main memory of a single machine or a cluster of commodity machines, traditional mechanisms for guaranteeing transaction durability---which typically involve synchronous log flushes---incur increasingly unappealing costs to otherwise lightweight transactions. Many applications have turned to periodically checkpointing full database state. However, existing checkpointing methods---even those which avoid freezing the storage layer---often come with significant costs to operation throughput, end-to-end latency, and total memory usage.         This paper presents Checkpointing Asynchronously using Logical Consistency (CALC), a lightweight, asynchronous technique for capturing database snapshots that  does not require a physical point of consistency to create a checkpoint, and avoids conspicuous latency spikes incurred by other database snapshotting schemes. Our experiments show that CALC can capture frequent checkpoints across a variety of transactional workloads with extremely small cost to transactional throughput and low additional memory usage compared to other state-of-the-art checkpointing systems.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Kun Ren"
      }, 
      {
        "name": "thaddeus Diamond"
      }, 
      {
        "name": "Daniel Abadi"
      }, 
      {
        "name": "Alexander Thomson"
      }
    ], 
    "type": "Research,", 
    "id": "839"
  }, 
  "956": {
    "title": "Matrix Sketching Over Sliding Windows", 
    "abstract": " Large-scale matrix computation becomes essential for many data data applications, and hence the problem of sketching matrix with small space and high precision has received extensive study for the past few years. This problem is often considered in the row-update  streaming model, where the data set is a matrix $A \\in \\mathbb{R}^{n \\times d}$, and the processor receives a row ($1\\times d$) of $A$ at each timestamp. The goal is to maintain a  smaller matrix (termed approximation matrix, or simply approximation) $B\\in \\mathbb{R}^{\\ell\\times d}$ as an approximation to $A$, such that the covariance error $\\|A^T A - B^TB\\|$ is small and $\\ell \\ll n$.  This paper studies continuous tracking approximations to the matrix defined by a sliding window of most recent rows. We consider both sequence-based and time-based window. We show that maintaining $A^TA$ exactly requires linear space in the sliding window model, as opposed to $O(d^2)$ space in the streaming model. With this observation, we present three general frameworks for matrix sketching on sliding windows. The sampling techniques give random samples of the rows in the window according to their squared norms. The \\textsf{Logarithmic Method} converts a {\\em mergeable} streaming matrix sketch into a matrix sketch on time-based sliding windows. The \\textsf{Dyadic Interval} framework converts arbitrary streaming matrix sketch into a matrix sketch on sequence-based sliding windows.  In addition to proving all algorithmic properties theoretically, we also conduct extensive empirical study with real datasets to demonstrate the efficiency of these algorithms.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Zhewei Wei"
      }, 
      {
        "name": "Xuancheng Liu"
      }, 
      {
        "name": "Feifei Li"
      }, 
      {
        "name": "Shuo Shang"
      }, 
      {
        "name": "Xiaoyong Du"
      }, 
      {
        "name": "Ji-Rong Wen"
      }
    ], 
    "type": "Research,", 
    "id": "956"
  }, 
  "375": {
    "title": "Micro-architectural Analysis of In-memory OLTP", 
    "abstract": "Micro-architectural behavior of traditional disk-based online transaction processing (OLTP) systems has been investigated extensively over the past couple of decades. Results show that traditional OLTP mostly underutilize the available micro-architectural resources. In-memory OLTP systems, on the other hand, process all the data in main-memory, and therefore, can omit the buffer pool. In addition, they usually adopt more lightweight concurrency control mechanisms, cache-conscious data structures and a cleaner codebase since they are usually designed from scratch. Hence, we expect significant differences in micro-architectural behavior when running OLTP on in-memory as opposed to disk-based database systems. In particular,  we expect that in-memory systems exploit micro architectural features such as instruction and data caches significantly better than disk-based systems. Surprisingly, the differences are not as pronounced as expected. This paper sheds light on the micro-architectural behaviour of in-memory database systems by analyzing and contrasting it to the behaviour of disk-based systems when running OLTP workloads. The results show that despite all the design changes in-memory OLTP exhibits very similar micro-architectural behavior to disk-based OLTP systems: more than half of the execution time goes to memory stalls where L1 instruction misses and the long-latency data misses from the last-level cache are the dominant factors in the overall stall time. Even though aggressive compilation optimizations can almost eliminate instruction misses, the reduction in instruction stalls amplifies the impact of last-level cache data misses. As a result, the number of instructions retired per cycle barely reaches one on machines that are able to retire up to four for both traditional disk-based and new generation in-memory transaction processing systems. ", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Utku Sirin"
      }, 
      {
        "name": "Pinar Tozun"
      }, 
      {
        "name": "Danica Porobic"
      }, 
      {
        "name": "Anastasia Ailamaki"
      }
    ], 
    "type": "Research", 
    "id": "375"
  }, 
  "890": {
    "title": "Multi-Source Uncertain Entity Resolution at Yad Vashem: Transforming Holocaust Victim Reports into People", 
    "abstract": "In this work we describe an entity resolution project performed at Yad Vashem, the central repository of holocaust-era information. The Yad Vashem dataset is unique with respect to classic entity resolution, by virtue of being both massively multi-source and by requiring multi-level entity resolution. With the abundance of information sources today, this project sets an example for future tasks requiring multi-source resolution on a big-data scale. We explore the benefits and shortcomings of using the MFIBlocks entity resolution algorithm in achieving the goals of the application. In particular, we provide a machine learning approach, based upon decision trees to transform soft clusters into probabilistic clustering of records into entities.    An extensive empirical evaluation demonstrates the unique properties of this dataset, highlighting the shortcomings of current methods and proposing avenues for future research in this realm.  ", 
    "subtype": "Industrial", 
    "authors": [
      {
        "name": "Tomer Sagi"
      }, 
      {
        "name": "Avigdor Gal"
      }, 
      {
        "name": "Omer Barkol"
      }, 
      {
        "name": "Ruth Bergman"
      }, 
      {
        "name": "Alexander Avram"
      }
    ], 
    "type": "Industrial", 
    "id": "890"
  }, 
  "422": {
    "title": "Ontological Pathfinding: Mining First-Order Knowledge from Large Knowledge Bases", 
    "abstract": "Recent years have seen a drastic rise in the construction of web-scale knowledge bases (e.g., Freebase, YAGO, DBPedia). These knowledge bases store structured information about real-world people, places, organizations, etc. However, due to the limitations of human knowledge and extraction algorithms, current knowledge bases are still far from complete. In this paper, we study the problem of mining first-order inference rules to facilitate knowledge expansion. We propose the Ontological Pathfinding algorithm (OP) that scales to web-scale knowledge bases via a series of parallelization and optimization techniques, including a new parallel rule mining algorithm that parallelizes multi-way join queries, a novel partitioning algorithm to break the learning tasks into smaller independent sub-tasks, and a pruning strategy to eliminate unsound and resource-consuming rules before applying them. Combining these techniques, we are able to develop a first rule learning system that scales to Freebase--the largest public knowledge base with 112 million entities and 388 million facts. We mine 36,625 inference rules in 34 hours; no existing system achieves this scale. ", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Yang Chen"
      }, 
      {
        "name": "Sean Goldberg"
      }, 
      {
        "name": "Daisy Zhe Wang"
      }, 
      {
        "name": "Soumitra Siddharth Johri"
      }
    ], 
    "type": "Research", 
    "id": "422"
  }, 
  "870": {
    "title": "Operator and Query Progress Estimation in Microsoft SQL Server Live Query Statistics", 
    "abstract": "We describe the design and implementation of the new Live Query Statistics feature in Microsoft SQL Server 2016. The functionality includes  overall query progress as well as progress of  individual operators in the query execution plan. Estimating overall progress of execution for a SQL query can be valuable to help decide whether the query should be terminated or allowed to run to completion.  Estimating progress of individual operators in the plan is often helpful in troubleshooting query performance. We build upon the extensive prior work on the query progress estimation problem and introduce new refinements that significantly improve accuracy of progress estimation. We report results of experiments on synthetic benchmarks and real customer workloads that demonstrate the importance of our new techniques and reveals difficult cases that remain open.", 
    "subtype": "Industrial", 
    "authors": [
      {
        "name": "Kukjin Lee"
      }, 
      {
        "name": "Christian Konig"
      }, 
      {
        "name": "Vivek Narasayya"
      }, 
      {
        "name": "Bolin Ding"
      }, 
      {
        "name": "Surajit Chaudhuri"
      }, 
      {
        "name": "Brent Ellwein"
      }, 
      {
        "name": "Alexey Eksarevskiy"
      }, 
      {
        "name": "Manbeen  Kohli"
      }, 
      {
        "name": "Praneeta Prakash"
      }, 
      {
        "name": "Jacob Wyant"
      }, 
      {
        "name": "Jiexing Li"
      }, 
      {
        "name": "Rimma Nehme"
      }, 
      {
        "name": "Jeffrey Naughton"
      }
    ], 
    "type": "Industrial", 
    "id": "870"
  }, 
  "974": {
    "title": "Optimization of Nested Queries using the NF2 Algebra", 
    "abstract": "A key promise of SQL is that the optimizer will find the most efficient execution plan, regardless of how the query is formulated. In general, query optimizers of modern database systems are able to keep this promise, with the notable exception of nested queries. While several optimization techniques for nested queries have been proposed, their adoption in practice has been limited. In this paper, we argue that the NF2 (non-first normal form) algebra, which was originally designed to process nested tables, is a better approach to nested query optimization as it fulfills two key requirements. First, the NF2 algebra can represent all types of nested queries as well as both existing and novel optimization techniques based on its equivalences. Second, performance benefits can be achieved with little changes to existing transformation-based query optimizers as the NF2 algebra is an extension of the relational algebra. ", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "J\u009frgen H\u009alsch"
      }, 
      {
        "name": "Michael Grossniklaus"
      }, 
      {
        "name": "Marc Scholl"
      }
    ], 
    "type": "Research,", 
    "id": "974"
  }, 
  "872": {
    "title": "Page As You Go: Piecewise Columnar Access In SAP HANA", 
    "abstract": "In-memory columnar databases such as SAP HANA achieve extreme performance by means of vector processing over logical units of main memory resident columns. The core in-memory algorithms can be challenged when the working set of an application does not fit into main memory. To deal with memory pressure, most in-memory columnar databases evict candidate columns (or tables) using a set of heuristics gleaned from recent workload. As an alternative approach, we propose to reduce the unit of load and eviction from column to a contiguous portion of the in-memory columnar representation, which we call a page. In this paper, we adapt the core algorithms to be able to operate with partially loaded columns while preserving the performance benefits of vector processing. Our approach has two key advantages. First, partial column loading reduces the mandatory memory footprint for each column, making more memory available for other purposes. Second, partial eviction extends the in-memory lifetime of partially loaded column. We present a new in-memory columnar implementation for our approach, that we term page loadable column. We design a new persistency layout and access algorithms for the encoded data vector of the column, the order-preserving dictionary, and the inverted index. We compare the performance attributes of page loadable columns with those of regular in-memory columns and present a use-case for page loadable columns for cold data in data aging scenarios. Page loadable columns are completely integrated in SAP HANA, and we present extensive experimental results that quantify the performance overhead and the resource consumption when these columns are deployed. ", 
    "subtype": "Industrial", 
    "authors": [
      {
        "name": "Reza Sherkat"
      }, 
      {
        "name": "Colin Florendo"
      }, 
      {
        "name": "Mihnea Andrei"
      }, 
      {
        "name": "Anil Goel"
      }, 
      {
        "name": "Anisoara Nica"
      }, 
      {
        "name": "Peter Bumbulis"
      }, 
      {
        "name": "Ivan Schreter"
      }, 
      {
        "name": "Guenter Radestock"
      }, 
      {
        "name": "Christian  Bensberg"
      }, 
      {
        "name": "Daniel Booss"
      }, 
      {
        "name": "Heiko Gerwens"
      }
    ], 
    "type": "Industrial", 
    "id": "872"
  }, 
  "882": {
    "title": "ParTime: Parallel Temporal Aggregation", 
    "abstract": "This paper presents ParTime, a parallel algorithm for temporal aggregation. Temporal aggregation is one of the most important, yet most complex temporal query operators.    It has been extensively studied in the past, but so far there has only been one attempt to parallelize this operator. ParTime supports data parallelism and has a number of additional   advantages: It supports the full bi-temporal data model, it requires no a-priori indexing, it supports shared computation, and it runs well on modern hardware (i.e., NUMA machines with large main memories).  We implemented ParTime in a parallel database system and carried out comprehensive performance experiments with a real workload from the airline industry and a synthetic benchmark, the TPC-BiH benchmark.  The results show that ParTime significantly outperforms any other available temporal database system. Furthermore,  the results show that ParTime is competitive as compared to the Timeline Index, the best known technique to process temporal queries from the research literature and which is based on pre-computation and indexing.    ", 
    "subtype": "Industrial", 
    "authors": [
      {
        "name": "Markus Pilman"
      }, 
      {
        "name": "Florian K\u009ahl"
      }, 
      {
        "name": "Martin Kaufmann"
      }, 
      {
        "name": "Donald Kossmann"
      }, 
      {
        "name": "Damien Profeta"
      }
    ], 
    "type": "Industrial", 
    "id": "882"
  }, 
  "889": {
    "title": "Potential and Pitfalls of Domain-Specific Information Extraction at Web Scale", 
    "abstract": "In many domains, a plethora of textual information is available on the web as news reports, blog posts, community portals, etc. Information extraction (IE) is the default technique to turn unstructured text into structured fact databases, but systematically applying IE techniques to web input requires highly complex systems, starting from focused crawlers over quality assurance methods to cope with the HTML input to long pipelines of natural language processing and IE algorithms. Although a number of tools for each of these steps exists, their seamless, flexible, and scalable combination into a web scale end-to-end text analytics system still is a true challenge.  In this paper, we report our experiences from building such a system for comparing the \"web view\" on health related topics with that derived from a controlled scientific corpus, i.e., Medline. The system combines a focused crawler, applying shallow text analysis and classification to maintain focus, with a sophisticated text analytic engine inside the Big Data processing system Stratosphere. We describe a practical approach to seed generation which led us crawl a corpus of ~1 TB web pages highly enriched for the biomedical domain. Pages were run through a complex pipeline of best-of-breed tools for a multitude of necessary tasks, such as HTML repair, boilerplate detection, sentence detection, linguistic annotation, parsing, and eventually named entity recognition for several types of entities. Results are compared with those from running the same pipeline (without the web-related tasks) on a corpus of 24 million scientific abstracts and a third corpus made of ~250K scientific full texts. We evaluate scalability, quality, and robustness of the employed methods and tools. The focus of this paper is to provide a large, real-life use case to inspire future research into robust, easy-to-use, and scalable methods for domain-specific IE at web scale. ", 
    "subtype": "Industrial", 
    "authors": [
      {
        "name": "Astrid Rheinl\u008ander"
      }, 
      {
        "name": "Mario Lehmann"
      }, 
      {
        "name": "Anja Kunkel"
      }, 
      {
        "name": "J\u009arg Meier"
      }, 
      {
        "name": "Ulf Leser"
      }
    ], 
    "type": "Industrial", 
    "id": "889"
  }, 
  "367": {
    "title": "Practical Private Range Search Revisited", 
    "abstract": "We consider a data owner that outsources its dataset to an untrusted server. The owner wishes to enable the server to answer range queries on a single attribute, without compromising the privacy of the data and the queries. There are several schemes on \"practical\" private range search (mainly in Databases venues) that attempt to strike a trade-off between efficiency and security. Nevertheless, these methods either lack provable security guarantees, or permit unacceptable privacy leakages. In this paper, we take an interdisciplinary approach, which combines the rigor of Security formulations and proofs with efficient Data Management techniques. We construct a wide set of novel schemes with realistic security/performance trade-offs, adopting the notion of Searchable Symmetric Encryption (SSE) primarily proposed for keyword search. Specifically, we reduce range search to multi-keyword search using range covering techniques with tree-like indexes. We demonstrate that, given any secure SSE scheme, the challenge boils down to (i) formulating leakages that arise from the index structure, and (ii) minimizing false positives incurred by some schemes under heavy data skew. We analytically detail the superiority of our proposals over prior work and experimentally confirm their practicality. Our paper is self-contained and accessible to both Security and Data Management practitioners.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Ioannis Demertzis"
      }, 
      {
        "name": "Stavros Papadopoulos"
      }, 
      {
        "name": "Odysseas Papapetrou"
      },
      {
        "name": "Antonios Deligiannakis"
      },
      {
        "name": "Minos Garofalakis"
      }
    ], 
    "type": "Research", 
    "id": "367"
  }, 
  "392": {
    "title": "Principled evaluation of differentially private algorithms using DPBench", 
    "abstract": "Differential privacy has become the dominant standard in the research community for strong privacy protection.  There has been a flood of research into query answering algorithms that meet this standard.  Algorithms are becoming increasingly complex, and in particular, the performance of many emerging algorithms is data dependent, meaning the distribution of the noise added to query answers may change depending on the input data.  Theoretical analysis typically only considers the worst case, making empirical study of average case performance increasingly important.  In this paper we propose a set of evaluation principles which we argue are essential for sound evaluation.  Based on these principles we propose DPBench, a novel evaluation framework for  standardized evaluation of privacy algorithms.  We then apply our benchmark to evaluate algorithms for answering 1- and 2-dimensional range queries. The result is a thorough empirical study of 15 published algorithms on a total of 27 datasets that offers new insights into algorithm behavior---in particular the influence of dataset scale and shape---and a more complete characterization of the state of the art.  Our methodology is able to resolve inconsistencies in prior empirical studies and place algorithm performance in context through comparison to simple baselines.  Finally, we pose open research questions  which we hope will guide future algorithm design.  ", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Michael Hay"
      }, 
      {
        "name": "Ashwin Machanavajjhala"
      }, 
      {
        "name": "Gerome Miklau"
      }, 
      {
        "name": "Yan Chen"
      }, 
      {
        "name": "Dan Zhang"
      }
    ], 
    "type": "Research", 
    "id": "392"
  }, 
  "388": {
    "title": "PrivTree: A Differentially Private Algorithm for Hierarchical Decompositions", 
    "abstract": "Given a set D of tuples defined on a domain Omega, we study differentially private algorithms for constructing a histogram over Omega to approximate the tuple distribution in D. Existing solutions for the problem mostly adopt a hierarchical decomposition approach, which recursively splits Omega into sub-domains and computes a noisy tuple count for each sub-domain, until all noisy counts are below a certain threshold. This approach, however, requires that we (i) impose a limit h on the recursion depth in the splitting of Omega and (ii) set the noise in each count to be proportional to h. The choice of h is a serious dilemma: a small h makes the resulting histogram too coarse-grained, while a large h leads to excessive noise in the tuple counts used in deciding whether sub-domains should be split. Furthermore, h cannot be directly tuned based on D; otherwise, the choice of h itself reveals private information and violates differential privacy.  To remedy the deficiency of existing solutions, we present PrivTree, a histogram construction algorithm that adopts hierarchical decomposition but completely eliminates the dependency on a pre-defined h. The core of PrivTree is a novel mechanism that (i) exploits a new analysis on the Laplace distribution and (ii) enables us to use only a constant amount of noise in deciding whether a sub-domain should be split, without worrying about the recursion depth of splitting. We demonstrate the application of PrivTree in modelling spatial data, and show that it can be extended to handle sequence data (where the decision in sub-domain splitting is not based on tuple counts but a more sophisticated measure). Our experiments on a variety of real datasets show that PrivTree considerably outperforms the states of the art in terms of data utility.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Jun Zhang"
      }, 
      {
        "name": "Xiaokui Xiao"
      }, 
      {
        "name": "Xing Xie"
      }
    ], 
    "type": "Research", 
    "id": "388"
  }, 
  "424": {
    "title": "Privacy Preserving Subgraph Matching on Large Graphs in Cloud", 
    "abstract": "The wide presence of large graph data and the increasing popularity of storing data in the cloud drive the needs for graph query processing on a remote cloud. But a fundamental challenge is to process user queries without compromising sensitive information. This work focuses on privacy preserving subgraph matching in a cloud server. The goal is to minimize the overhead on both cloud and client sides for subgraph matching, without compromising users\u00d5 sensitive information. To that end, we transform an original graph G into a privacy preserving graph Gk, which meets the requirement of an existing privacy model known as k-automorphism. By making use of the symmetry in a k-automorphic graph, a subgraph matching query can be efficiently answered using a graph Go, a small subset of Gk. This approach saves both space and query cost in the cloud server. In addition, we anonymize the original query graphs to protect their label information using label generalization technique. To reduce the search space for a subgraph matching query, we propose a cost model to select the more effective label combinations. The effectiveness and efficiency of our method are demonstrated through extensive experimental results on real datasets.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Zhao Chang"
      }, 
      {
        "name": "Lei Zou"
      }, 
      {
        "name": "Feifei Li"
      }
    ], 
    "type": "Research", 
    "id": "424"
  }, 
  "987": {
    "title": "PrivateClean: Data Cleaning and Differential Privacy", 
    "abstract": "Recent advances in differential privacy make it possible to guarantee user privacy while preserving the main characteristics of the data. However, consistent result estimation in after privacy is based on the assumption that the underlying data are accurate. Raw data are often dirty, and this places the burden of potentially expensive data cleaning on the data provider. This paper explores the link between data cleaning and differential privacy in a framework we call PrivateClean. We extend the well-studied randomized response model to show that it is compatible with subsequent extraction, transformation, and merging operations. PrivateClean includes a technique for creating private datasets of numerical and discrete-valued attributes, a formalism for privacy-preserving data cleaning, and techniques for answering \\sumfunc, \\countfunc, and \\avgfunc queries after cleaning. We show: (1) how the degree of privacy affects subsequent aggregate query accuracy, (2) how privacy potentially amplifies errors in a dataset, and (3) this analysis can be used to tune the degree of privacy. We validate these results on three real and synthetic datasets. ", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Sanjay Krishnan"
      }, 
      {
        "name": "Jiannan Wang"
      }, 
      {
        "name": "Tim Kraska"
      }, 
      {
        "name": "Ken Goldberg"
      }, 
      {
        "name": "Michael Franklin"
      }
    ], 
    "type": "Research,", 
    "id": "987"
  }, 
  "369": {
    "title": "Probabilistic Truss Decomposition: Concepts and Algorithms", 
    "abstract": "A key operation in network analysis is the discovery of cohesive subgraphs. The notion of k-truss has gained considerable popularity in this regard, based on its rich structure and efficient computability. However, many complex networks such as social, biological and communication networks feature uncertainty, best modeled using probabilities. Unfortunately the problem of discovering k-trusses in probabilistic graphs has received little attention to date.  In this paper, given a probabilistic graph G, number k and parameter _ _ (0, 1], we define a (k, _)-truss as a maximal connected subgraph H _ G, in which for each edge, the probability that it is contained in at least (k _ 2) triangles is at least _. We develop an efficient algorithm for decomposing a probabilistic graph into such maximal (k, _)-trusses. The above definition is local in that the \u00d2witness\u00d3 graphs that has the (k _ 2) triangles containing an edge in H may be quite different for distinct edges. To mitigate this, we also explore a \u00d2global\u00d3 notion: a global (k, _)-truss, in addition to being a local (k, _)-truss, has to satisfy the condition that the probability that H contains a k-truss is at least _. We show that unlike local (k,_)-truss, the global (k,_)-truss decomposition of a probabilistic graph is intractable. We propose a novel sampling scheme which enables approximate discovery of global (k,_)-trusses with high probability. Our extensive experiments on real and synthetic datasets demonstrate the efficiency and effectiveness of our proposed approach and the usefulness of the notions of local and global (k,_)-truss.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Xin Huang"
      }, 
      {
        "name": "Wei Lu"
      }, 
      {
        "name": "Laks Lakshmanan"
      }
    ], 
    "type": "Research", 
    "id": "369"
  }, 
  "935": {
    "title": "Publishing Attributed Social Graphs with Formal Privacy Guarantees", 
    "abstract": "Many data analysis tasks rely on the abstract of a graph to represent relations between entities, with attributes on the nodes and edges. Since the relationships encoded are often sensitive, we seek effective ways to release representative graphs which nevertheless protect the privacy of the data subjects. Prior work in this direction has focused primarily on the graph structure in isolation, and has not provided ways to handle richer graphs with correlated attributes.   We introduce an approach to release such graphs under the strong guarantee of differential privacy. We adapt existing graph models, and introduce a new one, and show how to augment them with meaningful privacy. This provides a complete workflow, where the input is a sensitive graph, and the output is a realistic synthetic graph. Our experimental study demonstrates that our process produces useful, accurate graph data. ", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Zachary Jorgensen"
      }, 
      {
        "name": "Ting Yu"
      }, 
      {
        "name": "Graham Cormode"
      }
    ], 
    "type": "Research,", 
    "id": "935"
  }, 
  "983": {
    "title": "Publishing Graph Degree Distribution with Node Differential Privacy", 
    "abstract": "Graph data publishing under node-differential privacy (node-DP) is challenging due to the huge sensitivity of queries.  However, since a node in graph data oftentimes represents a person, node-DP is necessary to achieve personal data protection.  In this paper, we investigate the problem of publishing the degree distribution of a graph under node-DP by exploring the projection approach to reduce the sensitivity.  We propose two approaches based on aggregation and cumulative histogram to publish the degree distribution.  The experiments demonstrate that our approaches greatly reduce the error of approximating the true degree distribution and have significant improvement over existing works.  We also present the introspective analysis for understanding the factors of publishing degree distribution with node-DP.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Wei-Yen Day"
      }, 
      {
        "name": "Ninghui Li"
      }, 
      {
        "name": "Min Lyu"
      }
    ], 
    "type": "Research,", 
    "id": "983"
  }, 
  "410": {
    "title": "Query Planning for Evaluating SPARQL Property Paths", 
    "abstract": "The extension of SPARQL in version 1.1 with property paths offers a type of regular path query for RDF graph databases. Such queries are difficult to optimize and evaluate efficiently, however. We have embarked on a project, Waveguide, to build a cost-based optimizer for SPARQL queries with property paths. Waveguide builds a query plan\u00d1a waveguide plan (WGP)\u00d1which guides the query evaluation. There are numerous choices in the construction of a plan, and a number of optimization methods, meaning the space of plans for a query can be quite large. Execution costs of plans for the same query can vary by orders of magnitude. We illustrate the types of optimizations this approach affords and the performance gains that can be obtained. A WGP\u00d5s costs can be estimated, which opens the way to cost-based optimization.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Nikolay Yakovets"
      }, 
      {
        "name": "Parke Godfrey"
      }, 
      {
        "name": "Jarek Gryz"
      }
    ], 
    "type": "Research", 
    "id": "410"
  }, 
  "926": {
    "title": "RDFind: Scalable Conditional Inclusion Dependency Discovery in RDF Datasets", 
    "abstract": "Inclusion dependencies (INDs) form an important integrity constraint on relational databases, supporting data management tasks, such as join path discovery and query optimization. Conditional inclusion dependencies (CINDs), which define including and included data in terms of conditions, allow to transfer these capabilities to RDF data. However, CIND discovery is computationally much more complex than IND discovery and the number of CINDs even on small RDF datasets are intractable. To cope with both problems, we first introduce the notion of pertinent CINDs with an adjustable relevance criterion to filter and rank CINDs based on their extent and implications among each other. Second, we present RDFind, a distributed system to efficiently discover all pertinent CINDs in RDF datasets. RDFind employs a lazy pruning strategy to drastically reduce the CIND search space. Also, its exhaustive parallelization strategy as well as robust data structures make it highly scalable. In our experimental evaluation, we show that RDFind is up to 419 times faster than the state-of-the-art, while considering a more general class of CINDs. Furthermore, it is capable of processing a very large dataset consisting of billions of triples, which was entirely infeasible before.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Sebastian Kruse"
      }, 
      {
        "name": "Anja Jentzsch"
      }, 
      {
        "name": "Thorsten Papenbrock"
      }, 
      {
        "name": "Zoi Kaoudi"
      }, 
      {
        "name": "Jorge Quian\u008e-Ruiz"
      }, 
      {
        "name": "Felix Naumann"
      }
    ], 
    "type": "Research,", 
    "id": "926"
  }, 
  "436": {
    "title": "ROLL: Fast In-Memory Generation of Gigantic Scale-free Networks", 
    "abstract": "Real-world graphs are not always publicly available or sometimes do not meet specific research requirements. These challenges call for generating synthetic networks that follow properties of the real-world networks. Barab\\'{a}si-Albert (BA) is a well-known model for generating scale-free graphs, i.e graphs with power-law degree distribution. In BA model, the network is generated through an iterative stochastic process called preferential attachment. Although BA is highly demanded, due to the inherent complexity of the preferential attachment, this model cannot be scaled to generate billion-node graphs.  In this paper, we propose ROLL-tree, a fast in-memory roulette wheel data structure that accelerates the BA network generation process by exploiting the statistical behaviors of the underlying growth model. Our proposed method has the following properties: (a) Fast: It performs +1000 times faster than the state-of-the-art on a single node PC; (b) Exact: It strictly follows the BA model, using an efficient data structure instead of approximation techniques; (c) Generalizable: It can be adapted for other ''rich-get-richer'' stochastic growth models. Our extensive experiments prove that ROLL-tree can effectively accelerate graph-generation through the preferential attachment process. On a commodity single processor machine, for example, ROLL-tree generates a scale-free graph of 1.1 billion nodes and 6.6 billion edges (the size of Yahoo's Webgraph) in 62 minutes while the state-of-the-art (SA) takes about four years on the same machine.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Ali Hadian"
      }, 
      {
        "name": "Sadegh Nobari"
      }, 
      {
        "name": "Behrouz Minaei-Bidgoli"
      }, 
      {
        "name": "Qiang Qu"
      }
    ], 
    "type": "Research", 
    "id": "436"
  }, 
  "692": {
    "title": "Range Thresholding on Streams", 
    "abstract": "This paper studies a type of continuous queries called {\\em range thresholding on streams} (RTS). Imagine the stream as an unbounded sequence of elements each of which is a real value. A query registers an interval, and must be notified as soon as a certain number of incoming elements fall into the interval. The system needs to support multiple queries simultaneously, and aims to minimize the space consumption and computation time.             Currently, all the solutions to this problem entail quadratic time $O(nm)$ to process $n$ stream elements and $m$ queries, which severely limits their applicability to only a small number of queries. We propose the first algorithm that breaks the quadratic barrier, by reducing the computation cost dramatically to $O(n + m)$, subject only to a polylogarithmic factor. The algorithm is general enough to guarantee the same on weighted versions of the queries even in $d$-dimensional space of any constant $d$. Its vast advantage over the previous methods in practical environments has been confirmed through extensive experimentation.  ", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Miao Qiao"
      }, 
      {
        "name": "Junhao Gan"
      }, 
      {
        "name": "Yufei Tao"
      }
    ], 
    "type": "Research,", 
    "id": "692"
  }, 
  "964": {
    "title": "Range-based Obstructed Nearest Neighbor Queries", 
    "abstract": "In this paper, we study a novel variant of obstructed nearest neighbor queries, namely, range-based obstructed nearest neighbor (RONN) search. A natural generalization of continuous obstructed nearest-neighbor (CONN), an RONN query retrieves the obstructed nearest neighbor for every point in a specified range. To process RONN, we first propose a CONN-Based (CONNB) algorithm as our baseline, which reduces the RONN query into a range query and four CONN queries processed using an R-tree. To address the shortcomings of the CONNB algorithm, we then propose a new RONN by R-tree Filtering (RONN-RF) algorithm, which explores effective filtering, also using R-tree. Next, we propose a new index, called O-tree, dedicated for indexing objects in the obstructed space. The novelty of O-tree lies in the idea of dividing the obstructed space into non-obstructed space, aiming to efficiently retrieve highly qualified candidates for RONN processing. We develop an O-tree construction algorithm and propose a space division scheme, called optimal obstacle balance (OOB) scheme, to address the tree balance problem. Accordingly, we propose an efficient algorithm, called RONN by O-tree Acceleration (RONN-OA), which exploits O-tree to accelerate query processing of RONN. In addition, we extend O-tree for indexing polygons. At last, we conduct a comprehensive performance evaluation using both real and synthetic datasets to validate our ideas and the proposed algorithms. The experimental result shows that the RONN-OA algorithm outperforms the two R-tree based algorithms significantly. Moreover, we show that the OOB scheme achieves the best tree balance in O-tree and outperforms two baseline schemes.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Huaijie Zhu"
      }, 
      {
        "name": "Xiaochun Yang"
      }, 
      {
        "name": "bin wang"
      }, 
      {
        "name": "Wang-Chien Lee"
      }
    ], 
    "type": "Research,", 
    "id": "964"
  }, 
  "916": {
    "title": "Real-time Video Recommendation Exploration", 
    "abstract": "Video recommendation has attracted growing attention in recent years. However, conventional techniques have limitations in real-time processing, accuracy or scalability for the large-scale video data. To address the deficiencies of current recommendation systems, we introduce some new techniques to provide real-time and accurate recommendations to users in the video recommendation system of Tencent Inc.  We develop a scalable online collaborative filtering algorithm based upon matrix factorization, with an adjustable updating strategy considering implicit feedback solution of different user actions. To select high-quality candidate videos for real-time top-N recommendation generation, we utilize additional factors like video type and time factor to compute similar videos. In addition, we propose the scalable implementation of our algorithm together with some optimizations to make the recommendations more efficient and accurate, including the demographic filtering and demographic training. To demonstrate the effectiveness and efficiency of our model, we conduct comprehensive experiments by collecting real data from Tencent Video. Furthermore, our video recommendation system is in production to provide recommendation services in Tencent Video, one of the largest video sites in China, and verifies its superiority in performance.", 
    "subtype": "Industrial", 
    "authors": [
      {
        "name": "Yanxiang Huang"
      }, 
      {
        "name": "Bin Cui"
      }, 
      {
        "name": "Jie Jiang"
      }, 
      {
        "name": "Kunqiang Hong"
      }, 
      {
        "name": "Wenyu Zhang"
      }, 
      {
        "name": "Yiran Xie"
      }
    ], 
    "type": "Industrial", 
    "id": "916"
  }, 
  "947": {
    "title": "Reducing the Storage Overhead of Main-Memory OLTP Databases with Hybrid Indexes", 
    "abstract": "Using indexes for query execution is crucial for achieving high performance in modern on-line transaction processing databases. For a main-memory database, however, these indexes consume a large fraction of the total memory available and are thus a major source of storage overhead of in-memory databases. To reduce this overhead, we propose using a two-stage index: The first stage ingests all incoming entries and is kept small for fast read and write operations. The index periodically migrates entries from the first stage to the second, which uses a more compact, read-optimized data structure. Our first contribution is hybrid index, a dual-stage index architecture that achieves both space efficiency and high performance. Our second contribution is Dual-Stage Transformation (DST), a general method for converting any order-preserving index structure into a hybrid index. Our third contribution is applying DST to three popular order-preserving index structures and evaluating them in both standalone microbenchmarks and a full in-memory DBMS using several transaction processing workloads. Our results show that hybrid indexes provide comparable throughput to the original ones while reducing the memory overhead by up to 70%.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Huanchen Zhang"
      }, 
      {
        "name": "David Andersen"
      }, 
      {
        "name": "Andy Pavlo"
      }, 
      {
        "name": "Michael Kaminsky"
      }, 
      {
        "name": "Lin Ma"
      }, 
      {
        "name": "Rui Shen"
      }
    ], 
    "type": "Research,", 
    "id": "947"
  }, 
  "923": {
    "title": "Remember Where You Came From: On The Second-Order Random Walk Based Proximity Measures", 
    "abstract": "Measuring the proximity between different nodes is a fundamental problem in graph analysis. Random walk based proximity measures have been shown to be effective and widely used. Most existing random walk measures are based on the first-order Markov model, i.e., they assume that the next step of the random surfer only depends on the current node. However, this assumption neither holds in many real-life applications nor captures the clustering structure in the graph. To address the limitation of the existing first-order measures, in this paper, we study the second-order random walk measures, which take the previously visited node into consideration. While the existing first-order measures are built on node-to-node transition probabilities, in the second-order random walk, we need to consider the edge-to-edge transition probabilities. Using incidence matrices, we develop simple and elegant matrix representations for the second-order proximity measures. A desirable property of the developed measures is that they degenerate to their original first-order forms when the effect of the previous step is zero. We further develop Monte Carlo methods to efficiently compute the second-order measures and provide theoretical performance guarantees. Experimental results show that in a variety of applications, the second-order measures can dramatically improve the performance compared to their first-order counterparts.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Yubao Wu"
      }, 
      {
        "name": "Yuchen Bian"
      }, 
      {
        "name": "Xiang Zhang"
      }
    ], 
    "type": "Research,", 
    "id": "923"
  }, 
  "399": {
    "title": "Robust Query Processing in Co-Processor-accelerated Databases", 
    "abstract": "Technology limitations are making the use of heterogeneous computing devices much more than an academic curiosity. In fact, the use of such devices is widely acknowledged to be the only promising way to achieve application-speedups that users urgently need and expect. However, building a robust and efficient query engine for heterogeneous co-processor environments is still a significant challenge.  In this paper, we identify two effects that limit performance in case co-processor resources become scarce. Cache thrashing occurs when the working set of queries does not fit into the co-processor\u00d5s data cache, resulting in performance degradations up to a factor of 24. Heap contention occurs when multiple operators run in parallel on a co-processor and when their accumulated memory footprint exceeds the main memory capacity of the co-processor, slowing down query execution by up to a factor of six.  We propose solutions for both effects. Data-driven operator placement avoids data movements when they might be harmful; query chopping limits co-processor memory usage and thus avoids contention. The combined approach\u00d1data-driven query chopping\u00d1achieves robust and scalable performance on co-processors. We validate our proposal with an open-source GPU-accelerated database engine and the popular star schema and TPC-H benchmarks.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Sebastian Bre\u00a7"
      }, 
      {
        "name": "Henning Funke"
      }, 
      {
        "name": "Jens Teubner"
      }
    ], 
    "type": "Research", 
    "id": "399"
  }, 
  "934": {
    "title": "Robust and Noise Resistant Wrapper Induction", 
    "abstract": "Wrapper induction is the problem of automatically inferring a query from annotated web pages of the same template. This query should not only select the annotated content accurately but also other content following the same template. Beyond accurately matching the template, we consider two additional requirements: (1) wrappers should be robust against a large class of changes to the web pages, and (2) the induction process should be noise resistant, i.e., tolerate slightly erroneous (e.g., machine generated) samples. Key to our approach is a query language that is powerful enough to permit accurate selection, but limited enough to force noisy samples to be generalized into wrappers that select the likely intended items. We introduce such a language as subset of XPATH and show that even for such a restricted language, inducing optimal queries according to a suitable scoring is infeasible. Nevertheless, our wrapper induction framework infers highly robust and noise resistant queries. We evaluate the queries on snapshots from web pages that change over time as provided by the Internet Archive, and show that the induced queries are as robust as the human-made queries. The queries often survive hundreds sometimes thousands of days, with many changes to the relative position of the selected nodes (including changes on template level). This is due to the few and discriminative anchor (intermediately selected) nodes of the generated queries. The queries are highly resistant against positive noise (up to 50%) and negative noise (up to 20%).", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Tim Furche"
      }, 
      {
        "name": "Jinsong Guo"
      }, 
      {
        "name": "Sebastian Maneth"
      }, 
      {
        "name": "christian Schallhart"
      }
    ], 
    "type": "Research,", 
    "id": "934"
  }, 
  "195": {
    "title": "SABER: Window-Based Hybrid Stream Processing for Heterogeneous Architectures", 
    "abstract": "Modern servers have become heterogeneous, often combining multicore CPUs with many-core GPGPUs. Such heterogeneous architectures have the potential to improve the performance of data-intensive stream processing applications, but they are not supported by current relational stream processing engines. For an engine to exploit a heterogeneous architecture, it must execute streaming SQL queries with sufficient data-parallelism to fully utilise all available heterogeneous processors, and decide how to use each in the most effective way. It must do this while respecting the semantics of streaming SQL queries, in particular with regard to window handling.  We describe SABER, a hybrid high-performance relational stream processing engine for CPUs and GPGPUs. SABER executes window-based streaming SQL queries in a data-parallel fashion using all available CPU and GPGPU cores. Instead of statically assigning query operators to heterogeneous processors, SABER employs a new adaptive heterogeneous lookahead scheduling strategy, which increases the share of queries executing on the processor that yields the highest performance. To hide data movement costs, SABER pipelines the transfer of stream data between different memory types and the CPU/GPGPU. Our experimental comparison against state-of-the-art engines shows that SABER increases processing throughput while maintaining low latency for a wide range of streaming SQL queries with small and large windows sizes. ", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Alexandros Koliousis"
      }, 
      {
        "name": "Matthias Weidlich"
      }, 
      {
        "name": "Raul Castro Fernandez"
      }, 
      {
        "name": "Paolo Costa"
      }, 
      {
        "name": "Alexander Wolf"
      }, 
      {
        "name": "Peter Pietzuch"
      }
    ], 
    "type": "Research", 
    "id": "195"
  }, 
  "365": {
    "title": "SHARE Interface in Flash Storage for Databases", 
    "abstract": "In the era of all-flash data centers in cloud computing, it is urgent to make open source database engines including tranditional relational DBMSs (e.g. MySQL/InnoDB) and emerging NoSQL storage engines (e.g. Couchbase) to be flash-optimized. For guaranteering the write atomicity which is critical for database consistency, many modern database storage engines are resorting to either redundant write or copy-on-write approach, both of which su_er from excessive write amplification, causing tardy performance and faster wear-out in flash storages. In order to tackle this write amplification problem in flash storage, this paper proposes a novel solution called SHARE. By calling SHARE, a new flash storage interface, database storage engines can explicitly remap the address mapping inside FTL so that they can, in combination with their original out-of-place update approach, achieve the write atomicity of data pages without any write ampfilication. By exploiting the address mapping available in every modern FTLs, the SHARE interface can make almost free the overhead of write amplification in database storage engine, which is a legacy of harddisk-based design principles. In addition, with SHARE, the compaction process, which is inevitable and time-consuming in NoSQL storage engines, can be completed in Couchbase without copying any data pages in flash storage. Our preliminary experimental results of SHARE-based MySQL/InnoDB and Couchbase on a real SSD development board show that it can significantly boost the database performance. In particular, the performance of compaction can be accelerated by more than an order of magnitude in terms of write time.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "GIHWAN OH"
      }, 
      {
        "name": "Chiyoung Seo"
      }, 
      {
        "name": "Ravi Mayuram"
      }, 
      {
        "name": "Yang-Suk Kee"
      }, 
      {
        "name": "Sang-Won Lee"
      }
    ], 
    "type": "Research", 
    "id": "365"
  }, 
  "976": {
    "title": "SLING: A Near-Optimal Index Structure for SimRank", 
    "abstract": "SimRank is a similarity measure for graph nodes that has numerous applications in practice. Scalable SimRank computation has been the subject of extensive research for more than a decade, and yet, none of the existing solutions can efficiently derive SimRank scores on large graphs with provable accuracy guarantees. In particular, the state-of-the-art solution requires up to a few seconds to compute a SimRank score in million-node graphs, and does not offer any worst-case assurance in terms of the query error.  This paper presents SLING, an efficient index structure for SimRank computation. SLING guarantees that each SimRank score returned has at most $\\epsilon$ additive error, and it answers any single-pair and single-source SimRank queries in $O(1/\\epsilon)$ and $O(n/\\epsilon)$ time, respectively. These time complexities are near-optimal, and are significantly better than the asymptotic bounds of the states of the art. Furthermore, SLING requires only $O(n/\\epsilon)$ space (which is also near-optimal) and $O(m/\\epsilon + n\\log \\frac{n}{\\delta}/\\epsilon^2)$ pre-computation time, where $\\delta$ is the failure probability of the preprocessing algorithm. We experimentally evaluate SLING with a variety of real-world graphs with up to several millions of nodes. Our results demonstrate that SLING is up to 20000 times (resp. 80 times) faster than competing methods for single-pair (resp. single-source) SimRank queries.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Boyu Tian"
      }, 
      {
        "name": "Xiaokui Xiao"
      }
    ], 
    "type": "Research,", 
    "id": "976"
  }, 
  "971": {
    "title": "SQL Schema Design", 
    "abstract": "Normalization helps us find a database schema at design time that can process the most frequent updates efficiently at run time. Unfortunately, relational normalization only works for idealized database instances in which duplicates and null markers are not present. On one hand, these features occur frequently in real-world data compliant with the industry standard SQL, and especially in modern application domains. On the other hand, the features impose challenges that have made it impossible so far to extend the existing forty year old normalization framework to SQL. We introduce a new class of functional dependencies and show that they provide the right notion for SQL schema design. Axiomatic and linear-time algorithmic characterizations of the associated implication problem are established. These foundations enable us to propose a Boyce-Codd normal form for SQL. Indeed, we justify the normal form by showing that it permits precisely those SQL instances which are free from data redundancy. Unlike the relational case, there are SQL schemata that cannot be converted into Boyce-Codd normal form. Nevertheless, for an expressive sub-class of our functional dependencies we establish a normalization algorithm that always produces a schema in Value-Redundancy free normal form. This normal form permits precisely those instances which are free from any redundant data value occurrences other than the null marker. Experiments show that our functional dependencies occur frequently in real-world data and that they are effective in eliminating redundant values from these data sets without loss of information.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Henning Koehler"
      }, 
      {
        "name": "Sebastian Link"
      }
    ], 
    "type": "Research,", 
    "id": "971"
  }, 
  "988": {
    "title": "Sample + Seek: Approximating Aggregates with Distribution Precision Guarantee", 
    "abstract": "Users demand interactive query response time in modern decision support applications even though data volumes are exponentially growing over time. As small error is usually tolerable in such applications, traditional approximate query processing (AQP) tackles this challenge by providing fast confidence-interval based estimations for groups in the answer to an aggregation query. However, we argue that the semantics of confidence-interval guarantees falls short when there are many groups in the answer. Instead, we propose that an aggregation query\u00d5s answer be normalized as a distribution over groups, and introduce the notion of distribution precision of an estimated answer. This notion measures accuracy with the L2 distance between distributions of the estimated answer and the exact one. In this paper, we study how to provide fast approximate answers to aggregation queries with distribution precision guaranteed. We propose a novel sampling scheme called measure-biased sampling. We introduce how to use pre-drawn (measure-biased and uniform) samples with size sub-linear to the database size to answer aggregation queries. For queries with highly selective predicates, we propose two new on-disk indexes, measure-augmented inverted index and low-frequency group index, to aid in-memory samples. Those indexes have sizes linear to the database size, but we only need a constant number of index seeks to answer an aggregation query under the distribution-precision requirement. In addition to deriving rigorous theoretical guarantees, we conduct experimental study to compare our system with alternatives in both synthetic and real enterprise datasets. In our experiments, compared to a commercial database product with support for column-store, our system provides a median speed-up of 100x with 5% distribution error in answers.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Bolin Ding"
      }, 
      {
        "name": "Silu Huang"
      }, 
      {
        "name": "Surajit Chaudhuri"
      }, 
      {
        "name": "Kaushik Chakrabarti"
      }, 
      {
        "name": "Chi Wang"
      }
    ], 
    "type": "Research,", 
    "id": "988"
  }, 
  "370": {
    "title": "Sampling-Based Query Re-Optimization", 
    "abstract": "Despite of decades of work, query optimizers still make mistakes on \"difficult\" queries because of bad cardinality estimates, often due to the interaction of multiple predicates and correlations in the data. In this paper, we propose a low-cost post-processing step that can take a plan produced by the optimizer, detect when it is likely to have made such a mistake, and take steps to fix it. Specifically, our solution is a sampling-based iterative procedure that requires almost no changes to the original query optimizer or query evaluation mechanism of the system. We show that this indeed imposes low overhead and catches cases where three widely used optimizers (PostgreSQL and two commercial systems) make large errors. ", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Wentao Wu"
      }, 
      {
        "name": "Jeffrey Naughton"
      }, 
      {
        "name": "Harneet Singh"
      }
    ], 
    "type": "Research", 
    "id": "370"
  }, 
  "951": {
    "title": "Scalable Approximate Query Tracking over Highly Distributed Data Streams", 
    "abstract": "The recently-proposed Geometric Monitoring (GM) method has provided a general tool for the distributed monitoring of arbitrary non-linear queries over streaming data observed by a collection of remote sites, with numerous practical applications.  Still, as we demonstrate in this paper, GM-based techniques can suffer from serious scalability issues with increasing numbers of remote sites. In this paper, we propose novel techniques that effectively tackle the aforementioned scalability problems by exploiting a carefully designed sample of the remote sites for efficient approximate query tracking. Our novel sampling-based scheme utilizes a sample of cardinality proportional to $\\sqrt{N}$ (compared to $N$ for the original GM), where $N$ is the number of sites in the network, to perform the monitoring process. By means of the aforementioned sample, our experimental evaluation over a variety of real-life data streams demonstrates that our techniques can significantly reduce the communication cost during distributed monitoring with controllable, predefined accuracy guarantees.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Nikos Giatrakos"
      }, 
      {
        "name": "Antonios Deligiannakis"
      }, 
      {
        "name": "Minos Garofalakis"
      }
    ], 
    "type": "Research,", 
    "id": "951"
  }, 
  "413": {
    "title": "Scalable Pattern Sharing over Event Streams", 
    "abstract": "Complex Event Processing (CEP) has emerged as a technology of choice for high performance event analytics in time-critical decision-making applications. It is becoming increasingly difficult to support high-performance event processing queries due to the combination of the rising number and complexity of event pattern queries and the increasing velocity of event streams. In this work we design the SPASS (Scalable PAttern Sharing over event Streams) framework that successfully tackles these demanding CEP workloads. Our SPASS optimizer identifies effective sharing opportunities among CEP queries by leveraging time-based event correlations among queries.  The problem of pattern sharing is shown to be NP-hard by reducing the Minimum Substring Cover problem to the pattern sharing problem.  Thereafter, the SPASS optimizer is designed that finds a shared pattern plan in polynomial-time covering all sequence patterns while still guaranteeing an optimality bound.  To execute this shared pattern plan, the SPASS runtime employs stream transactions that assure concurrent shared maintenance and re-use of sub-patterns across queries.  Our SPASS framework is shown to achieve over 16 fold performance improvement for a wide range of experiments compared to the state-of-the-art solution.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Medhabi Ray"
      }, 
      {
        "name": "Chuan Lei"
      }, 
      {
        "name": "Elke Rundensteiner"
      }
    ], 
    "type": "Research", 
    "id": "413"
  }, 
  "428": {
    "title": "Scaling Multi-core OLTP Under High Contention", 
    "abstract": "Although significant recent progress has been made in improving the multi-core scalability of high throughput transactional database systems, modern systems still fail to achieve scalable throughput for workloads involving frequent access to highly contended data. Most of this inability to achieve high throughput is explained by the fundamental constraints involved in guaranteeing ACID --- the addition of cores results in more concurrent transactions accessing the same contended data for which access must be serialized in order to guarantee isolation. Thus, linear scalability for contended workloads is impossible. However, there exist flaws in many modern architectures that exacerbate their poor scalability, and result in throughput that is much worse than fundamentally required by the workload.  In this paper we identify two prevalent design principles that are present in many (but not all) transactional database systems that limit their multi-core scalability on contended workloads: the multi-purpose nature of the threads of execution in these systems, and the lack of advanced planning of data access. We demonstrate the deleterious results of these design principles on multi-core scalability by implementing a prototype system, Orthrus, that is motivated by the principles of separation of database component functionality and advanced planning of transactions. We find that these two principles alone result in significantly improved scalability on high-contention workloads, and an order of magnitude increase in throughput for a non-trivial subset of these contended workloads. ", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Kun Ren"
      }, 
      {
        "name": "Jose Faleiro"
      }, 
      {
        "name": "Daniel Abadi"
      }
    ], 
    "type": "Research", 
    "id": "428"
  }, 
  "963": {
    "title": "Sequential Data Cleaning: A Statistical Approach", 
    "abstract": "Errors are prevalent in data sequences, such as GPS trajec- tories or sensor readings. Existing methods on cleaning se- quential data employ a constraint on value changing speeds and perform constraint-based repairing. While such speed constraints are effective in identifying large spike errors, the small errors that do not significantly deviate from the truth and indeed satisfy the speed constraints can hardly be iden- tified and repaired. To handle such small errors, in this pa- per, we propose a statistical based cleaning method. Rather than declaring a broad constraint of max/min speeds, we model the probability distribution of speed changes. The repairing problem is thus to maximize the likelihood of the sequence w.r.t. the probability of speed changes. We for- malize the likelihood-based cleaning problem, show its np- hardness, devise exact algorithms, and propose several ap- proximate/heuristic methods to trade off effectiveness for efficiency. Experiments on real data sets (in various appli- cations) demonstrate the superiority of our proposal.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Aoqian Zhang"
      }, 
      {
        "name": "Shaoxu Song"
      }, 
      {
        "name": "Jianmin Wang"
      }
    ], 
    "type": "Research,", 
    "id": "963"
  }, 
  "435": {
    "title": "Set-based Similarity Search for Time Series", 
    "abstract": "A fundamental problem of time series is the k nearest neighbor (k-NN) query processing. Existing methods are not fast enough for large dataset. In this paper, we propose a novel approach, STS3, processing k-NN queries by transforming time series to a set and measuring similarity under Jaccard metric. Our approach is faster than most of the existing methods due to the efficient similarity search for sets. Besides, we developed index, a pruning and an approximation technique to speed up the k-NN query processing. As shown in the experimental results, all of them could accelerate the query processing effectively.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Jinglin Peng"
      }, 
      {
        "name": "Hongzhi Wang"
      }, 
      {
        "name": "Jianzhong Li"
      }, 
      {
        "name": "Hong Gao"
      }
    ], 
    "type": "Research", 
    "id": "435"
  }, 
  "379": {
    "title": "Sharing-Aware Outlier Analytics over High-Volume Data Streams", 
    "abstract": "Real-time analytics of anomalous phenomena on streaming data typically relies on processing a large variety of continuous outlier detection requests, each configured with different parameter settings. The processing of such complex outlier analytics workloads is resource consuming due to the algorithmic complexity of the outlier mining process. In this work we propose a sharing-aware multi-query execution strategy for outlier detection on data streams called SOP. A key insight of SOP is to transform the problem of handling a \\emph{multi-query outlier} analytics workload into a \\emph{single-query skyline} computation problem. We prove that the output of the skyline computation process corresponds to the minimal information needed for determining the outlier status of any point in the stream. Based on this new formulation, we design a customized skyline algorithm called K-SKY that leverages the \\textit{domination relationships} among the streaming data points to minimize the number of data points that must be evaluated for supporting multi-query outlier detection. Based on this K-SKY algorithm, our SOP solution achieves minimal utilization of both computational and memory resources for the processing of these complex outlier analytics workload. Our experimental study demonstrates that SOP consistently outperforms the state-of-art solutions by three orders of magnitude in CPU time, while only consuming 5\\% of their memory footprint $-$ a clear win-win. Furthermore, SOP is shown to scale to large workloads composed of thousands of parameterized queries. ", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Lei Cao"
      }, 
      {
        "name": "Jiayuan Wang"
      }, 
      {
        "name": "Elke Rundensteiner"
      }
    ], 
    "type": "Research", 
    "id": "379"
  }, 
  "Ind_104": {
    "title": "Shasta: Interactive Reporting At Scale", 
    "abstract": "", 
    "subtype": "Industrial", 
    "authors": [
      {
        "name": "Gokul Nath Babu Manoharan"
      }, 
      {
        "name": "Stephan Ellner"
      }, 
      {
        "name": "Karl Schnaitter"
      }, 
      {
        "name": "Sridatta Chegu"
      }, 
      {
        "name": "Alejandro Estrella Balderrama"
      }, 
      {
        "name": "Stephan Gudmundson"
      }, 
      {
        "name": "Apurv Gupta"
      }, 
      {
        "name": "Ben Handy"
      }, 
      {
        "name": "Bart Samwel"
      }, 
      {
        "name": "Chad Whipkey"
      }, 
      {
        "name": "Larysa Aharkava"
      }, 
      {
        "name": "Himani Apte"
      }, 
      {
        "name": "Nitin Gangahar"
      }, 
      {
        "name": "Jun Xu"
      }, 
      {
        "name": "Shivakumar Venkataraman"
      }, 
      {
        "name": "Divyakant Agrawal"
      }, 
      {
        "name": "Jeffrey D. Ullman"
      }
    ], 
    "type": "Industrial", 
    "id": "Ind_104"
  }, 
  "968": {
    "title": "Simba: Efficient In-Memory Spatial Analytics", 
    "abstract": "Large spatial data becomes ubiquitous. As a result, it is critical to provide fast, scalable, and high-throughput spatial queries and analytics for numerous applications in location-based services (LBS). Traditional spatial databases and spatial analytics systems are disk-based and optimized for IO efficiency. But increasingly, data are stored and processed in memory to achieve low latency, and CPU time becomes the new bottleneck. We present the Simba (Spatial In-Memory Big data Analytics) system that offers scalable and efficient in-memory spatial query processing and analytics for big spatial data. Simba is based on Spark and runs over a cluster of commodity machines. In particular, Simba extends the Spark SQL engine to support rich spatial queries and analytics through both SQL and the DataFrame API. It introduces the concept and construction of indexes over RDDs in order to work with big spatial data and complex spatial operations. Lastly, Simba implements an effective query optimizer, which leverages its indexes and novel spatial-aware optimizations, to achieve both low latency and high throughput. Extensive experiments over large data sets demonstrate Simba\u00d5s superior performance compared against other spatial analytics system.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Dong Xie"
      }, 
      {
        "name": "Feifei Li"
      }, 
      {
        "name": "Bin Yao"
      }, 
      {
        "name": "Gefei Li"
      }, 
      {
        "name": "Liang Zhou"
      }, 
      {
        "name": "Minyi Guo"
      }
    ], 
    "type": "Research,", 
    "id": "968"
  }, 
  "985": {
    "title": "Similarity Join over Array Data", 
    "abstract": "Scientific applications are generating an ever-increasing volume of multi-dimensional data that are largely processed inside distributed array databases and frameworks. Similarity join is a fundamental operation across scientific workloads that requires complex processing over an unbounded number of pairs of multi-dimensional points. In this paper, we introduce a novel distributed similarity join operator for multi-dimensional arrays. Unlike immediate extensions to array join and relational similarity join, the proposed operator minimizes the overall data transfer and network congestion while providing load-balancing, without completely repartitioning and replicating the input arrays. We define formally array similarity join and present the design, optimization strategies, and evaluation of the first array similarity join operator.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Weijie Zhao"
      }, 
      {
        "name": "Florin Rusu"
      }, 
      {
        "name": "Bin Dong"
      }, 
      {
        "name": "John Wu"
      }
    ], 
    "type": "Research,", 
    "id": "985"
  }, 
  "899": {
    "title": "SparkR: Scaling R Programs with Spark", 
    "abstract": "R is a popular statistical programming language with a number of extensions that support data processing and machine learning tasks.  However, interactive data analysis in R is usually limited as the R runtime is single threaded and can only process data sets that fit in a single machine\u00d5s memory. We present SparkR, an R package that provides a frontend to Apache Spark and uses Spark\u00d5s distributed computation engine to enable large scale data analysis from the R shell. We describe the main design goals of SparkR, discuss how the high-level DataFrame API enables scalable computation and present some of the key details of our implementation.", 
    "subtype": "Industrial", 
    "authors": [
      {
        "name": "Shivaram Venkataraman"
      }, 
      {
        "name": "Zongheng Yang"
      }, 
      {
        "name": "Davies Liu"
      }, 
      {
        "name": "Eric Liang"
      }, 
      {
        "name": "Hossein Falaki"
      }, 
      {
        "name": "Xiangrui Meng"
      }, 
      {
        "name": "Reynold Xin"
      }, 
      {
        "name": "Ali Ghodsi"
      }, 
      {
        "name": "Michael Franklin"
      }, 
      {
        "name": "Ion Stoica"
      }, 
      {
        "name": "Matei Zaharia"
      }
    ], 
    "type": "Industrial", 
    "id": "899"
  }, 
  "945": {
    "title": "Speedup Graph Processing by Graph Ordering", 
    "abstract": "The CPU cache performance is one of the key issues to efficiency in database systems. It is reported that cache miss latency takes a half of the execution time in database systems. To improve the CPU cache performance, there are studies to support searching including cache-oblivious, and cache-conscious trees.  In this paper, we focus on CPU speedup for graph computing in general by reducing the CPU cache miss ratio for different graph algorithms. The approaches dealing with trees are not applicable to graphs which are complex in nature. In this paper, we explore a general approach to speed up CPU computing, in order to further enhance the efficiency of the graph algorithms without changing the graph algorithms (implementations) and the data structures used. That is, we aim at designing a general solution that is not for a specific graph algorithm, neither for a specific data structure. The approach studied in this work is graph ordering, which is to find the optimal permutation among all nodes in a given graph by keeping nodes that will be frequently accessed together locally, to minimize the CPU cache miss ratio. We prove the graph ordering problem is NP-hard, and give a basic algorithm with a bounded approximation. To improve the time complexity of the basic algorithm, we further propose a new algorithm to reduce the time complexity and improve the efficiency with new optimization techniques based on a new data structure. We conducted extensive experiments to evaluate our approach in comparison with other 9 possible graph orderings (such as the one obtained by METIS) using 8 large real graphs and 9 representative graph algorithms. We confirm that our approach can achieve high performance by reducing the CPU cache miss ratios significantly.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Hao Wei"
      }, 
      {
        "name": "Jeffrey Xu Yu"
      }, 
      {
        "name": "Can LU"
      }, 
      {
        "name": "Xuemin Lin"
      }
    ], 
    "type": "Research,", 
    "id": "945"
  }, 
  "989": {
    "title": "Spheres of Influence for More Effective Viral Marketing", 
    "abstract": "Given a social network, a probabilistic contagion model, and one node $s$, what is the set of nodes that would get infected if $s$ get infected? We call this the \\emph{sphere of influence} of $s$. Due to the stochastic nature of the contagion model we need to define a notion of ``expected'' or ``typical'' cascade: this is a set of nodes which is the closest to all the possible cascades starting from $s$.  We formalize the Typical Cascade problem which requires, for a given source node $s$, to find the set of nodes minimizing the expected Jaccard distance to all the possible cascades from $s$. The expected cost of a typical cascade also provides us a measure of the \\emph{stability} of cascade propagation, i.e., how much random cascades from a source node $s$ deviate from the ``typical'' cascade. In this sense source nodes with lower expected costs are more reliable.  We characterize the hardness of our problem, but show that a method based on $(1)$ sampling random cascades and $(2)$ computing their Jaccard Median, can obtain a multiplicative approximation with only $O(\\log n)$ samples. We thus devise an index that allows to efficiently retrieve the sphere of influence for any node in the network.  Finally, we propose an approach to the influence maximization problem based on the spheres of influence and set cover. Trough an exhaustive evaluation using real-world networks and different methods of assigning the influence probability to each edge, we show that our approach \\emph{outperforms in quality} the theoretically optimal greedy algorithm.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Yasir Mehmood"
      }, 
      {
        "name": "Francesco Bonchi"
      }, 
      {
        "name": "David Garcia-Soriano"
      }
    ], 
    "type": "Research,", 
    "id": "989"
  }, 
  "927": {
    "title": "Stop-and-Stare: Optimal Sampling Algorithms for Viral Marketing in Billion-scale Networks", 
    "abstract": "Influence Maximization (IM), that seeks a small set of key users who spread the influence widely into the network, is a core problem in multiple domains. It finds applications in viral marketing, epidemic control, and assessing cascading failures within complex systems. Despite the huge amount of effort, IM in billion-scale networks such as Facebook, Twitter, and World Wide Web has not been satisfactorily solved. Even the state-of-the-art methods such as TIM+ and IMM may take days on those networks.  In this paper, we propose SSA and D-SSA, two novel sampling frameworks for IM-based viral marketing problems. SSA and D-SSA are up to 1000 times faster than the SIGMOD'15 best method, IMM, while providing the same (1-1/e-\\epsilon)-approximation guarantee. Underlying our frameworks is an innovative Stop-and-Stare strategy in which they stop at exponential check points to verify (stare) if there is adequate statistical evidence on the solution quality. Theoretically, we prove that SSA and D-SSA are the first approximation algorithms that use (asymptotically) minimum numbers of samples, meeting strict theoretical thresholds characterized for IM. The absolute superiority of SSA and D-SSA are confirmed through extensive experiments on real network data for IM and an another topic-aware viral marketing marketing problem, named TVM.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Hung Nguyen"
      }, 
      {
        "name": "My Thai"
      }, 
      {
        "name": "Thang Dinh"
      }
    ], 
    "type": "Research,", 
    "id": "927"
  }, 
  "373": {
    "title": "Streaming Algorithms for Robust Distinct Elements", 
    "abstract": "We study the problem of estimating distinct elements in the data stream model, which has a central role in traffic monitoring, query optimization, data mining and data integration. Different from all previous work, we study the problem in the noisy data setting, where two different looking items in the stream may reference the same entity (determined by a distance function and a threshold value), and the goal is to estimate the number of distinct entities in the stream. In this paper, we formalize the problem of robust distinct elements, and develop space and time-efficient streaming algorithms for datasets in the Euclidean space, using a novel technique we call bucket sampling.  We also extend our algorithmic framework to other metric spaces by establishing a connection between bucket sampling and the theory of locality sensitive hashing. Moreover, we formally prove that our algorithms are still effective under small distinct elements ambiguity. Our experiments demonstrate the practicality of our algorithms.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Di Chen"
      }, 
      {
        "name": "Qin Zhang"
      }
    ], 
    "type": "Research", 
    "id": "373"
  }, 
  "933": {
    "title": "System-X: A Relational Engine for Graph Processing", 
    "abstract": "There are two types of high-performance graph processing engines: low- and high-level engines. Low-level engines (Galois, PowerGraph, Snap) provide optimized data structures and computation models but require users to write low-level imperative code; hence ensuring that efficiency is the burden of the user. In high-level engines users write in query languages like datalog (SociaLite) or SQL (Grail). High-level engines are easier to use but are orders of magnitude slower than the low-level graph engines. We present System-X, a high-level engine that supports a rich datalog-like query language and achieves performance comparable to that of low-level engines. At the core of System-X's design is a new class of join algorithms that satisfy strong theoretical guarantees, but have thus far not achieved  performance comparable to that of specialized graph processing engines. To achieve high performance, System-X introduces a new join engine architecture, including a novel query optimizer and data layouts that leverage single-instruction multiple data (SIMD) parallelism. With this architecture, System-X outperforms high-level approaches by up to three orders of magnitude on graph pattern queries, PageRank, and Single-Source Shortest Paths (SSSP), and is an order of magnitude faster than many standard low-level baselines. We validate that System-X competes with the best-of-breed low-level engine (Galois), achieving comparable performance on PageRank and at most 3x worse performance on SSSP.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Christopher Aberger"
      }, 
      {
        "name": "Susan Tu"
      }, 
      {
        "name": "Kunle Olukotun"
      }, 
      {
        "name": "Christopher Re"
      }
    ], 
    "type": "Research,", 
    "id": "933"
  }, 
  "955": {
    "title": "T-Part: Partitioning of Transactions for Onward-Pushing in Deterministic Database Systems", 
    "abstract": "The deterministic database systems have recently been shown to yield high throughput on a cluster of commodity machines while ensuring the strong consistency between replicas, provided that the data can be well-partitioned on these machines. However, data partitioning can be suboptimal for many reasons in real-world applications. In this paper, we present T-Part, a transaction execution engine that partitions transactions in a deterministic database system to deal with the unforeseeable workloads or workloads whose data are hard to partition. By modeling the dependency between transactions as a T-graph and continuously partitioning that graph, T-Part allows each transaction to know which later transactions on other machines will read its writes so that it can push onward the writes to those latter transactions immediately after committing. This onward pushing reduces the chance that the latter transactions stall due to the unavailability of remote data. T-Part also opens up numerous opportunities for sophisticated optimization of data movement and transaction execution, such as deciding which transactions to replicate/reorder to achieve better transaction partitioning. We implement a prototype for T-Part. Extensive experiments are conducted and the results demonstrate the effectiveness of T-Part. ", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Shan-Hung Wu"
      }, 
      {
        "name": "Tsai-Yu Feng"
      }, 
      {
        "name": "Meng-Kai Liao"
      }, 
      {
        "name": "Shao-Kan Pi"
      }, 
      {
        "name": "Yu-Shan Lin"
      }
    ], 
    "type": "Research,", 
    "id": "955"
  }, 
  "419": {
    "title": "TARDiS: Making Sense of Weak Consistency", 
    "abstract": "This paper presents the design and implementation of TARDiS, (Transactional Asynchronously Replicated Divergent Store), a transaction key-value store explicitly designed for weakly consistent systems. Reasoning about these systems is hard, as neither causal consistency nor per-object eventual convergence can satisfactorily allow applications to deal with the incidence of write-write conflicts. TARDiS instead exposes as its fundamental abstraction the set of conflicting branches that arise in weakly consistent systems. It achieves this through a new concurrency control mechanism: branch on conflict. On the one hand, TARDiS presents applications with the comfortable abstraction of sequential storage, keeping application logic simple. On the other, TARDiS provides them, when needed, with the tools and context necessary to merge branches atomically, when and how applications want, giving them flexibility. Since branch-on-conflict in TARDiS is fast, weakly consistent applications can benefit from adopting it not only for operations issued by different sites, but also, when appropriate, for conflicting local operations. Our results show that TARDiS successfully reduces coding complexity for weakly consistent applications while judiciously branching on conflict can improve throughput of the local site by two to six times.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Natacha Crooks"
      }, 
      {
        "name": "Youer Pu"
      }, 
      {
        "name": "Nancy Estrada"
      }, 
      {
        "name": "Trinabh Gupta"
      }, 
      {
        "name": "Lorenzo Alvisi"
      }, 
      {
        "name": "Allen Clement"
      }
    ], 
    "type": "Research", 
    "id": "419"
  }, 
  "408": {
    "title": "THEMIS: Fairness in Federated Stream Processing under Overload", 
    "abstract": "  Federated stream processing systems, which utilise nodes from multiple   independent domains, can be found increasingly in multi-provider cloud   deployments, internet of things systems, collaborative sensing applications    and large-scale grid systems. To pool resources from several sites and take advantage of   local processing, submitted queries are split into query fragments, which are   executed collaboratively by different sites. When supporting many concurrent   users, however, queries may exhaust available processing resources, thus   requiring constant load shedding. Given that individual sites have autonomy   over how they allocate query fragments on their nodes, it is an open   challenge how to ensure global fairness on processing quality   experienced by queries in a federated scenario.     We describe THEMIS, a federated stream processing system for resource-starved,   multi-site deployments. It executes queries in a globally fair   fashion and provides users with constant feedback on the experienced   processing quality for their queries. THEMIS associates stream data with its   Source Information Content (SIC), a metric that quantifies the   contribution of that data towards the query result, based on the amount of   source data used to generate it. We provide the BALANCE-SIC distributed load shedding   algorithm that aims to balance the SIC values of result data. Our extensive    evaluation validates that the BALANCE-SIC algorithm yields balanced SIC values across   queries as measured with the Jain's index fairness metric. Our approach also    incurs a low execution time overhead.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Evangelia Kalyvianaki"
      }, 
      {
        "name": "Marco Fiscato"
      }, 
      {
        "name": "Theodoros Salonidis"
      }, 
      {
        "name": "Peter Pietzuch"
      }
    ], 
    "type": "Research", 
    "id": "408"
  }, 
  "426": {
    "title": "TableShare: Results from a Multi-Year SQL-as-a-Service Experiment", 
    "abstract": "We analyze the workload from a multi-year deployment of a database-as-a-service platform targeting scientists and data scientists with minimal database experience.  Our hypothesis was that relatively minor changes to the way databases are delivered can increase their use in ad hoc analysis environments. The web-based TableShare system emphasizes easy dataset-at-a-time ingest, relaxed schemas and automatic schema inference, easy view creation and sharing, and full SQL support. We find that these features helped attract workloads typically associated with scripts and files rather than relational databases: complex analytics, routine processing pipelines, data publishing, and collaborative analysis. Quantitatively, these workloads are characterized by shorter dataset \u00d2lifetimes\u00d3, higher query complexity, and higher data complexity. We find evidence of research labs using SQL to replace scripts in one-off data analysis, pay-as-you-go schematization, and ad hoc data sharing. We find that relational models and languages are sufficient to support ad hoc analytics in science, but that the \u00d2delivery vector\u00d3 for the technology strongly influences use. We conclude that a new class of relational systems emphasizing short-term, ad hoc analytics over permanent schemas can improve uptake of relational databases in attention-intensive data science contexts. Our contributions include a system design for delivering databases into these contexts, a description of a public research query workload dataset released to advance research in analytic data systems, and an initial analysis of the workload that provides evidence of new use cases undersupported in existing systems.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Shrainik Jain"
      }, 
      {
        "name": "Bill Howe"
      }, 
      {
        "name": "Dominik Moritz"
      }, 
      {
        "name": "Ed Lazowska"
      }, 
      {
        "name": "Dan Halperin"
      }
    ], 
    "type": "Research", 
    "id": "426"
  }, 
  "900": {
    "title": "The Snowflake Elastic Data Warehouse", 
    "abstract": "We live in the golden age of distributed computing. Public cloud platforms now offer virtually unlimited compute and storage resources on demand. At the same time, the Software-as-a-Service (SaaS) model brings enterprise-class systems to users who previously could not afford such systems due to their cost and complexity. Alas, traditional data warehousing systems are struggling to fit into this new environment. For one thing, they have been designed for fixed resources and are thus unable to leverage the cloud's elasticity. For another thing, their dependence on complex ETL pipelines and physical tuning is at odds with the flexibility and freshness requirements of the cloud's new types of semi-structured data and rapidly evolving workloads.  We decided a fundamental redesign was in order. Our mission was to build an enterprise-ready data warehousing solution for the cloud. The result is the Snowflake Elastic Data Warehouse, or \"Snowflake\" for short. Snowflake is a multi-tenant, transactional, secure, highly scalable and elastic system with full SQL support and built-in extensions for semi-structured and schema-less data. The system is offered as a pay-as-you-go service in the Amazon cloud. Users upload their data to the cloud and can immediately manage and query it using familiar tools and interfaces. Implementation began in late 2012 and Snowflake has been generally available since June 2015. Today, Snowflake is used in production by a growing number of small and large organizations alike. The system runs several million queries per day over multiple petabytes of data.  In this paper, we describe the design of Snowflake and its novel multi-cluster, shared-data architecture. The paper highlights some of the key features of Snowflake: extreme elasticity and availability, semi-structured and schema-less data, time travel, and end-to-end security. It concludes with lessons learned and an outlook on ongoing work.", 
    "subtype": "Industrial", 
    "authors": [
      {
        "name": "Benoit Dageville"
      }, 
      {
        "name": "Thierry Cruanes"
      }, 
      {
        "name": "Marcin Zukowski"
      }, 
      {
        "name": "Vadim Antonov"
      }, 
      {
        "name": "Artin Avanes"
      }, 
      {
        "name": "Jon Bock"
      }, 
      {
        "name": "Jonathan Claybaugh"
      }, 
      {
        "name": "Daniel Engovatov"
      }, 
      {
        "name": "Martin Hentschel"
      }, 
      {
        "name": "Jiansheng Huang"
      }, 
      {
        "name": "Allison Lee"
      }, 
      {
        "name": "Ashish Motivala"
      }, 
      {
        "name": "Abdul Munir"
      }, 
      {
        "name": "Steven Pelley"
      }, 
      {
        "name": "Peter Povinec"
      }, 
      {
        "name": "Greg Rahn"
      }, 
      {
        "name": "Spyridon Triantafyllis"
      }, 
      {
        "name": "Philipp Unterbrunner"
      }
    ], 
    "type": "Industrial", 
    "id": "900"
  }, 
  "397": {
    "title": "TicToc: Time-Traveling Optimistic Concurrency Control", 
    "abstract": "Concurrency control for on-line transaction processing (OLTP) data- base management systems (DBMSs) is a nasty game. Achieving higher performance on emerging many-core systems is becoming increasingly difficult. Previous research has shown that timestamp allocation and management in a DBMS\u00d5s concurrency control al- gorithm is the key bottleneck that prevents the system from scaling up to support a larger number of simultaneous transactions. In this paper we present TicToc, a new optimistic concurrency control algorithm that avoids the scalability and concurrency bot- tlenecks of prior T/O schemes. TicToc relies on a novel and prov- ably correct data-driven timestamp management protocol. Instead of assigning timestamps to transactions, this protocol assigns read and write timestamps to data items and uses them to lazily com- pute a valid commit timestamp for each transaction. TicToc re- moves the need for centralized timestamp allocation, and commits transactions that would be aborted by conventional T/O schemes. We implemented TicToc along with three other concurrency con- trol algorithms in an in-memory, shared-everything OLTP DBMS and compared their performance on different workloads. Our re- sults show that TicToc achieves up to 92% better throughput while reducing the abort rate by 3.3_ than these previous algorithms.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Xiangyao Yu"
      }, 
      {
        "name": "Andy Pavlo"
      }, 
      {
        "name": "Daniel Sanchez"
      }, 
      {
        "name": "Srinivas Devadas"
      }
    ], 
    "type": "Research", 
    "id": "397"
  }, 
  "412": {
    "title": "Time Adaptive Sketches (Ada-Sketches) for Summarizing Data Streams", 
    "abstract": "Obtaining frequency information of data streams, in limited space, is a well-recognized problem in literature.  A number of recent practical applications (such as those in computational advertising) require temporally-aware solutions:  obtaining historical count statistics for both time-points as well as time-ranges. In these scenarios, accuracy of estimates is typically more important for recent instances than for older ones; we call this desirable property as ``\\emph{Time Adaptiveness}\". With this observation,~\\cite{Proc:Matusevych_UAI12} introduced the ``Hokusai\" technique based on count-min sketches for estimating frequencies of any given item at any given time.   The proposed approach is problematic in practice as its memory requirements grow linearly with time and it produces discontinuities in the estimation accuracy.  In this work, we describe a new method,``\\emph{Time Adaptive Sketches}\" (Ada-sketches), that overcomes these limitations, while extending and providing a strict generalization of several existing popular sketching algorithms.  The core idea of our method is inspired by the well-known digital Dolby noise reduction procedure that dates back to 1960s.  Theoretical analysis presented could be of independent interest in itself, as it provides clear results for the time-adaptive nature of the errors. Experimental evaluation on real streaming datasets demonstrates the superiority of the described method over Hokusai in estimating point and range queries over time.  The method is simple to implement and offers a variety of design choices for future extensions. The simplicity of the procedure and the method's generalization of classic sketching techniques give hope for wide applicability of Ada-sketches in practice.  ", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Anshumali Shrivastava"
      }, 
      {
        "name": "Christian Konig"
      }, 
      {
        "name": "Mikhail Bilenko"
      }
    ], 
    "type": "Research", 
    "id": "412"
  }, 
  "420": {
    "title": "To Join or Not to Join? Thinking Twice about Joins before Feature Selection", 
    "abstract": "Closer integration of machine learning (ML) with data processing is a booming area in both the data management industry and academia. Almost all ML toolkits assume that the input is a single table, but many datasets are not stored as single tables due to normalization. Thus, analysts often perform key-foreign key joins to obtain features from all base tables and apply a feature selection method, either explicitly or implicitly, with the aim of improving accuracy. In this work, we show theoretically that the features brought in by such joins can usually be ignored without affecting ML accuracy significantly, i.e., we can \"avoid joins safely\". However, we then identify a subtle technical issue caused by avoiding joins that might decrease accuracy significantly in some cases, and analyze this issue theoretically. Using simulations, we validate our analysis and measure the effects of various properties of normalized data on accuracy. We apply our analysis to design easy to understand decision rules to predict when it is safe to avoid joins in order to help analysts exploit this runtime-accuracy tradeoff. Experiments with multiple real normalized datasets show that our rules are able to accurately predict when joins can be avoided safely, and in some cases, this yielded significant runtime improvements for some popular feature selection methods.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Arun Kumar"
      }, 
      {
        "name": "Jeffrey Naughton"
      }, 
      {
        "name": "Jignesh Patel"
      }, 
      {
        "name": "Xiaojin Zhu"
      }
    ], 
    "type": "Research", 
    "id": "420"
  }, 
  "406": {
    "title": "Top-k Relevant Semantic Place Retrieval on Spatial RDF Data", 
    "abstract": "RDF data are traditionally accessed using structured query languages, such as SPARQL. However, this requires users to understand the language as well as the RDF schema. Keyword search on RDF data aims at relieving the user from these requirements; the user only inputs a set of keywords and the goal is to find small RDF subgraphs which contain all keywords. At the same time, popular RDF knowledge bases also include spatial semantics, which opens the road to location-based search operations. In this work, we propose and study a novel location-based keyword search query on RDF data. The objective of top-k relevant semantic places (kSP) retrieval is to find RDF subgraphs which contain the query keywords and are rooted at spatial entities close to the query location. The novelty of kSP queries is that they are location-aware and that they do not rely on the use of structured query languages. We design a basic method for the processing of kSP queries. To further accelerate kSP retrieval, two pruning approaches and a data preprocessing technique are proposed. Extensive empirical studies on two real datasets demonstrate the superior and robust performance of our proposals compared to the basic method.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Jieming Shi"
      }, 
      {
        "name": "Dingming Wu"
      }, 
      {
        "name": "Nikos Mamoulis"
      }
    ], 
    "type": "Research", 
    "id": "406"
  }, 
  "380": {
    "title": "Topic Exploration in Spatio-Temporal Document Collections", 
    "abstract": "Huge amounts of data with both spatial and temporal information (e.g., geo-tagged tweets) are being generated. Such data can be modeled as spatio-temporal documents and they have been widely used to share and spread personal updates, spontaneous ideas, and breaking news. Consequently, it is of great interest to explore topics in a collection of spatio-temporal documents.  In this paper, we study the problem of mining topics from spatio-temporal documents within a user specified bounded region and timespan, to provide users with insights about events, trends, and public concerns within the specified region and time period. We propose a novel algorithm that is able to efficiently combine two pre-trained topic models learnt from two document sets within a bounded error, based on which we develop an efficient approach to mining topics from a large number of spatio-temporal documents within a region and a timespan. Our experimental results show that our proposal is able to improve the runtime by at least an order of magnitude compared with the baselines. Meanwhile, the effectiveness of our proposed method is close to the baselines.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Kaiqi Zhao"
      }, 
      {
        "name": "Lisi Chen"
      }, 
      {
        "name": "Gao Cong"
      }
    ], 
    "type": "Research", 
    "id": "380"
  }, 
  "418": {
    "title": "Tornado: A System for Real-Time Iterative Analysis over Evolving Data", 
    "abstract": "There is an increasing demand for real-time iterative analysis over evolving data. In this paper, we propose a novel execution model to allow users to obtain timely results at given instants. We notice that a loop starting from a good initial guess usually converges fast. Hence we organize the execution of iterative methods over evolving data into a main loop and several branch loops. The main loop is responsible for the gathering of inputs and maintains the approximation to the timely results. When the precise results are requested by the user, a branch loop is forked from the main loop and iterates until convergence to obtain the precise results. Using the approximation of the main loop, the branch loop can start from a place near to the fixed-point and converges quickly to return accurate results.  As loops must gather inputs and approximate results simultaneously, we develop a novel partially asynchronous iteration model to enhance the timeliness. The partially asynchronous iteration model can achieve fine-grained updates while ensuring correctness for most iterative methods. By tuning the degree of asynchronism, users can also easily weigh the performance and fault tolerance.  Based on the proposed execution model of loops and iterations, we design and implement a prototype system named Tornado on top of Storm. Tornado provides a graph-parallel programming model which eases the programming of most real-time iterative analysis tasks. The reliability is also enhanced by provisioning efficient fault tolerance mechanisms. Empirical evaluation conducted on Tornado validates that various real-time iterative analysis tasks can improve their performance and efficiently tolerate failures with our execution model.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "XIAOGANG SHI"
      }, 
      {
        "name": "Bin Cui"
      }, 
      {
        "name": "Yingxia Shao"
      }, 
      {
        "name": "Yunhai Tong"
      }
    ], 
    "type": "Research", 
    "id": "418"
  }, 
  "430": {
    "title": "Towards Best Region Search with Submodular Monotone Aggregate Function", 
    "abstract": "The increasing popularity and growth of mobile devices and location-based services enable us to utilize large-scale geo-tagged data to support novel location-based applications. This paper introduces a novel problem called the \\textit{best region search} (\\emph{BRS}) problem and provides efficient solutions to it. Given a set $O$ of spatial objects, a submodular monotone aggregate score function, and the size $a\\times b$ of a query rectangle, the \\emph{BRS} problem aims to find $a\\times b$ rectangular region such that the \\textit{aggregate score} of the spatial objects inside the region is maximized. This problem is fundamental to support several real-world applications such as \\textit{most influential region} search (\\eg the best location for a billboard to attract most audience) and \\textit{most diversified region} search (\\eg region with most diverse facilities). We propose an efficient algorithm called \\emph{SliceBRS} to find the exact answer to the \\emph{BRS} problem. Furthermore, we propose an approximate solution called \\emph{CoverBRS} and prove that the answer found by it is bounded by a constant. Our experimental study with real-world datasets and applications demonstrates the effectiveness and superiority of our proposed algorithms.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Kaiyu Feng"
      }, 
      {
        "name": "Gao Cong"
      }, 
      {
        "name": "Sourav S Bhowmick"
      }, 
      {
        "name": "Wen-Chih Peng"
      }, 
      {
        "name": "Chunyan Miao"
      }
    ], 
    "type": "Research", 
    "id": "430"
  }, 
  "421": {
    "title": "Towards Globally Optimal Crowdsourcing Quality Management", 
    "abstract": "We study crowdsourcing quality management, that is, given worker responses to a set of tasks, our goal is to jointly estimate the true answers for the tasks, as well as the quality of the workers. Prior work on this problem relies primarily on applying Expectation-Maximization (EM) on the underlying maximum likelihood problem to estimate true answers as well as worker quality. Unfortunately, EM only provides a locally optimal solution rather than a globally optimal one. Other solutions to the problem (that do not leverage EM) fail to provide global optimality guarantees as well. In this paper, we focus on filtering, where tasks require the evaluation of a yes/no predicate, and rating, where tasks elicit integer scores from a finite domain. We design algorithms for finding the global optimal estimates of correct task answers and worker quality for the underlying maximum likelihood problem, and characterize the complexity of these algorithms. Our algorithms conceptually consider all mappings from tasks to true answers (typically a very large number), leveraging two key ideas to reduce, by several orders of magnitude, the number of mappings under consideration, while preserving optimality. We also demonstrate that these algorithms often find more accurate estimates than EM-based algorithms. This paper makes an important contribution towards under- standing the inherent complexity of globally optimal crowdsourcing quality management.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Akash Das Sarma"
      }, 
      {
        "name": "Aditya Parameswaran"
      }, 
      {
        "name": "Jennifer Widom"
      }
    ], 
    "type": "Research", 
    "id": "421"
  }, 
  "887": {
    "title": "Towards a Hybrid Design for Fast Query Processing in DB2 with BLU Acceleration Using Graphical Processing Units: A Technology Demonstration", 
    "abstract": "In this paper, we show how we use Nvidia GPUs and host CPU cores for faster query processing in a DB2 database using BLU Acceleration (DB2's column store technology). Moreover, we show the benefits and problems of using hardware accelerators (more specifically GPUs) in a real commercial Relational Database Management System (RDBMS). We investigate the effect of off-loading specific database operations to a GPU, and show how doing so results in a significant performance improvement. We then demonstrate that for some queries, using just CPU to perform the entire operation is more beneficial. While we use some of Nvidia's fast kernels for operations like sort, we have also developed our own high performance kernels for operations such as group by and aggregation. Finally, we show how we use a dynamic design that can make use of optimizer metadata to intelligently choose a GPU kernel to run. For the first time in the literature, we use benchmarks representative of customer environments to gauge the performance of our prototype, the results of which show that we can get a speed increase upwards of 2x, using a realistic set of queries. ", 
    "subtype": "Industrial", 
    "authors": [
      {
        "name": "Sina Meraji"
      }, 
      {
        "name": "Berni Schiefer"
      }, 
      {
        "name": "Lan Pham"
      }, 
      {
        "name": "Lee Chu"
      }, 
      {
        "name": "Peter Kokosielis"
      }, 
      {
        "name": "Adam Storm"
      }, 
      {
        "name": "Wayne Young"
      }, 
      {
        "name": "Chang Ge"
      }, 
      {
        "name": "Geoffrey Ng"
      }, 
      {
        "name": "Kajan Kanagaratnam"
      }
    ], 
    "type": "Industrial", 
    "id": "887"
  }, 
  "382": {
    "title": "Towards a Non-2PC Transaction Management in Distributed Database Systems", 
    "abstract": "Shared-nothing architecture has been widely used in distributed databases to achieve good scalability. While it offers superior performance for single-partition transactions (i.e., transactions whose data are hosted on a single data partition), the overhead of processing distributed transactions (i.e., transactions whose data are stored over multiple data partitions) can degrade the system performance significantly. The key contributor to the degradation is due to the expensive two-phase commit (2PC) protocol for preserving the atomicity of distributed transaction processing. In this paper, we propose a transaction management scheme called LEAP to eliminate the 2PC protocol within distributed transaction processing. Instead of distributing the transaction, LEAP converts any distributed transaction into a local transaction through gathering the ownership of its required data at the tuple granularity. This benefits the processing locality and facilitates adaptive data repartitioning with respect to the alteration of data access pattern. Based on LEAP we develop an online transaction processing (OLTP) system and compare it with the state-of-the-art distributed in-memory OLTP system, H-Store, which relies on the 2PC protocol for distributed transaction processing, and H^L-store, a H-store that makes use of LEAP. Results of an extensive experimental evaluation show that LEAP outperforms 2PC by a wide margin, especially for workloads characteristic of certain locality of cross-partition data access.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Qian Lin"
      }, 
      {
        "name": "Pengfei Chang"
      }, 
      {
        "name": "Gang Chen"
      }, 
      {
        "name": "Beng Chin Ooi"
      }, 
      {
        "name": "Kian-Lee Tan"
      }, 
      {
        "name": "Zhengkui Wang"
      }
    ], 
    "type": "Research", 
    "id": "382"
  }, 
  "921": {
    "title": "Transaction Healing: Scaling Optimistic Concurrency Control on Multicores", 
    "abstract": "Today's main-memory databases can support very high transaction rate for OLTP applications. However, when massive amounts of concurrent transactions contend on the same data records, the system performance can deteriorate significantly. This is especially the case when scaling transaction processing with optimistic concurrency control (OCC) on multicore machines. In this paper, we propose a new concurrency-control mechanism, called transaction healing, that exploits program semantics to scale the conventional OCC towards dozens of cores even under highly contended workloads. Transaction healing captures the dependencies across operations within a transaction prior to its execution. Instead of blindly rejecting a transaction once its validation fails, the proposed mechanism judiciously restores any non-serializable operation and heals inconsistent transaction states as well as query results according to the extracted dependencies. Transaction healing can partially update the membership of read/write sets when processing dependent transactions. Such overhead, however, is largely reduced by carefully avoiding false aborts and rearranging validation orders. We implemented the idea of transaction healing in THEDB, a main-memory database prototype that provides full ACID guarantee with a scalable commit protocol. By evaluating THEDB on a 48-core machine with two widely-used benchmarks, we confirm that transaction healing can scale near-linearly, yielding significantly higher transaction rate than the state-of-the-art OCC implementations.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Yingjun Wu"
      }, 
      {
        "name": "Chee Yong Chan"
      }, 
      {
        "name": "Kian-Lee Tan"
      }
    ], 
    "type": "Research,", 
    "id": "921"
  }, 
  "395": {
    "title": "Unleashing Parallelism in Multi-core Databases via Dependency Tracking", 
    "abstract": "Multicore in-memory databases rely on traditional concur- rency control schemes such as 2-phase-locking (2PL) or op- timistic concurrency control (OCC). Unfortunately, when the workload exhibits a non-trivial amount of contention, both 2PL and OCC sacrifice multi-core parallelism. In this paper, we describe a new concurrency control scheme, inter- leaving constrained concurrency control (IC3), which pro- vides serializability while allowing for parallel execution of conflicting transactions. Given a user transaction consisting of multiple data accesses, IC3 selectively synchronizes some of the accesses to preclude unsafe interleaving according to an offline analysis of the transaction workload. Evaluations on a 64-core machine using a set of OLTP workloads like TPC-C, TPC-E and SEATS show that IC3 outperforms tradi- tional concurrency control schemes. The performance gains are particularly pronounced when the workload exhibits high contention.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Zhaoguo Wang"
      }, 
      {
        "name": "Yang Cui"
      }, 
      {
        "name": "Han Yi"
      }, 
      {
        "name": "Shuai Mu"
      }, 
      {
        "name": "haibo Chen"
      }, 
      {
        "name": "Jinyang Li"
      }
    ], 
    "type": "Research", 
    "id": "395"
  }, 
  "504": {
    "title": "UpBit: Scalable In-Memory Updatable Bitmap Indexing", 
    "abstract": "Bitmap indexes are widely used in both scientific and commercial databases. They bring fast read performance for specific types of queries, such as equality and selective range queries, by binning values. A major drawback, however, is that updating a bitmap index is particularly costly because it requires both decoding and encoding a bitvector (bitvectors are always kept compressed to minimize storage footprint). Today, more and more applications need support for both reads and writes, blurring the boundaries between analytical processing and transaction processing. This requires new system designs and access methods that support general updates and offer competitive read performance.  In this paper, we propose scalable in-memory Updatable Bitmap indexing (UpBit), which offers efficient updates, without hurting read performance. UpBit relies on two design points. First, in addition to the main bitvector for each domain value, UpBit maintains an update bitvector, to keep track of updated values. Effectively, every update can now be directed to a highly-compressible, easy-to-update bitvector. While update bitvectors double the amount of uncompressed data, they are sparse, and as a result their compressed size is kept small. Second, we introduce fence pointers in all update bitvectors which allow for efficient retrieval of a value at an arbitrary position. Using both synthetic and real-life data, we demonstrate that UpBit significantly outperforms state-of-the-art bitmap indexes for workloads that contain both reads and updates. In particular, compared to update-optimized bitmap index designs UpBit is 15-29x faster in terms of update time and 2.7x faster in terms of read performance. In addition, compared to read-optimized bitmap index designs UpBit achieves efficient and scalable updates (51-115x lower update latency), while allowing for comparable read performance, having up to 8% overhead.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Manos Athanassoulis"
      }, 
      {
        "name": "Zheng Yan"
      }, 
      {
        "name": "Stratos Idreos"
      }
    ], 
    "type": "Research,", 
    "id": "504"
  }, 
  "901": {
    "title": "VectorH: taking SQL-on-Hadoop to the next level", 
    "abstract": "In this paper we describe VectorH: a new SQL-on-Hadoop system built on top of the fast Vectorwise analytical database system. VectorH achieves fault tolerance and scalable data storage by relying on HDFS, extending the state-of-the-art in SQL-on-Hadoop systems by instrumenting the HDFS block replication policy to ensure local reads under most circumstances. VectorH integrates with YARN for workload management, achieving a high degree of elasticity . Even though HDFS is an append-only filesystem, and it supports ordered table storage, VectorH can accommodate trickle updates through Positional Delta Trees (PDTs), a differential update structure that can be queried efficiently. We describe the main technical extensions to single-server Vectorwise that turned it into a Hadoop-based  MPP system, in terms of workload management, parallel query optimization and execution, HDFS storage, transaction processing and Spark integration. In the evaluation section we compare VectorH with HAWQ, Impala, SparkSQL and Hive, showing orders of magnitude better  performance than these competitors. ", 
    "subtype": "Industrial", 
    "authors": [
      {
        "name": "Andrei Costea"
      }, 
      {
        "name": "Adrian Ionescu"
      }, 
      {
        "name": "Bogdan Raducanu"
      }, 
      {
        "name": "Michal Switakowski"
      }, 
      {
        "name": "Cristian Barca"
      }, 
      {
        "name": "Juliusz Sompolski"
      }, 
      {
        "name": "Alicja Luszczak"
      }, 
      {
        "name": "Michal Szafranski"
      }, 
      {
        "name": "Giel De Nijs"
      }, 
      {
        "name": "Peter Boncz"
      }
    ], 
    "type": "Industrial", 
    "id": "901"
  }, 
  "384": {
    "title": "Data Blocks: Hybrid OLTP and OLAP on Compressed Storage using both Vectorization and Compilation", 
    "abstract": "This work aims at reducing the main-memory footprint in high performance hybrid OLTP&OLAP databases, while retaining high query performance and transactional throughput. For this purpose an innovative compressed columnar storage format for cold data, called Data Blocks is intro- duced. Data Blocks, further incorporate a new light-weight index structure called Positional SMA, that narrows scan ranges within Data Blocks even if the entire block cannot be ruled out. To achieve highest OLTP performance the compression schemes of Data Blocks are very light-weight, such that OLTP transactions can still quickly access individual tuples \u00d0 Setting this storage scheme apart from those used in specialized analytical databases, where data must usually be bit-unpacked. So far high-performance analytical systems use either vectorized query execution or \u00d2just-in-time\u00d3 (JIT) query compilation. The fine-grained adaptivity of Data Blocks necessitates the integration of the best features of each approach by an interpreted vectorized scan sub-system feeding into JIT-compiled query pipelines. Experimental evaluation of our full-fledged hybrid OLTP&OLAP database system shows that Data Blocks accelerate performance on a variety of query workloads while retaining high transaction throughput.", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Harald Lang"
      }, 
      {
        "name": "Tobias Muehlbauer"
      }, 
      {
        "name": "Florian Funke"
      }, 
      {
        "name": "Peter Boncz"
      }, 
      {
        "name": "Thomas Neumann"
      }, 
      {
        "name": "Alfons Kemper"
      }
    ], 
    "type": "Research", 
    "id": "384"
  }, 
  "965": {
    "title": "Wander Join: Online Aggregation via Random Walks", 
    "abstract": "Joins are expensive, and online aggregation over joins was proposed to mitigate the cost, which offers users a nice and flexible tradeoff between query efficiency and accuracy in a continuous, online fashion. However, the state-of-the-art approach, in both internal and external memory, is based on ripple join, which is still very expensive and even needs unrealistic assumptions (e.g., tuples in a table are stored in random order). This paper proposes a new approach the wander join algorithm, to the online aggregation problem by performing random walks over the underlying join graph.  Wander join produces independent but non-uniform samples, which gives huge performance gains over the uniform but non-independent samples returned by ripple join. We also design an optimizer that chooses the optimal plan for conducting the random walks without having to collect any statistics a priori. Wander join works for different types of joins including chain, acyclic, cyclic joins, with selection predicates and group-by clauses. It easily extends to $\\theta$-joins as well.  Extensive experiments using the TPC-H benchmark have demonstrated the superior performance of wander join over ripple join in both internal and external memory. We have also implemented and tested wander join in the latest version of PostgreSQL; the results show its excellent efficiency and effectiveness in a full fledged, commercial level DBMS.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Feifei Li"
      }, 
      {
        "name": "Bin Wu"
      }, 
      {
        "name": "Ke Yi"
      }, 
      {
        "name": "Zhuoyue Zhao"
      }
    ], 
    "type": "Research,", 
    "id": "965"
  }, 
  "429": {
    "title": "iBFS: Concurrent Breadth-First Graph Traversal on GPUs", 
    "abstract": "Breadth-First Search (BFS) is a key graph algorithm with many important applications. In this work, we focus on a special class of graph traversal algorithm - concurrent BFS - where multiple breadth-first traversals are performed si- multaneously on the same graph. We have designed and developed a new approach called iBFS that is able to run i concurrent BFSes from i distinct source vertices, very effi- ciently on Graphics Processing Units (GPUs). iBFS consists of three novel designs. First, iBFS develops a single GPU kernel for joint traversal of concurrent BFS to take advan- tage of shared frontiers across different instances. Second, outdegree-based GroupBy rules enables iBFS to selectively run a group of BFS instances which further maximizes the frontier sharing within such a group. Third, iBFS brings ad- ditional performance benefit by utilizing highly optimized bitwise operations on GPUs, which allows a single GPU thread to inspect a vertex for concurrent BFS instances. We evaluate iBFS on a wide spectrum of graph benchmarks and show that iBFS on a single GPU runs up to 30_ faster than executing different BFS instances sequentially, and on 112 GPUs achieves near linear speedup with the maximum performance of 57,267 billion traversed edges per second (TEPS).", 
    "subtype": "Research", 
    "authors": [
      {
        "name": "Hang Liu"
      }, 
      {
        "name": "Howie Huang"
      }, 
      {
        "name": "Yang Hu"
      }
    ], 
    "type": "Research", 
    "id": "429"
  }, 
  "972": {
    "title": "iOLAP: Incremental OLAP for Interactive Analysis on Big Data", 
    "abstract": "The size of data and the complexity of analytics continue to grow along with the need for timely and cost-effective analysis. However, the growth of computation power cannot keep up with the growth of data. This calls for a paradigm shift from traditional batch OLAP processing model to an incremental OLAP processing model. In this paper, we propose iOLAP, an incremental OLAP query engine that provides a smooth trade-off between query accuracy and latency, and fulfills a full spectrum of user requirements from approximate but timely query execution to a more traditional  accurate query execution. iOLAP enables interactive incremental query processing using a novel mini-batch execution model---given an OLAP query, iOLAP first randomly partitions the input dataset into smaller sets (mini-batches) and then incrementally processes through these partitions by executing a delta update query on each mini-batch,  where each subsequent delta update query computes an update based on the output of the previous one.  The key idea behind iOLAP is a novel delta update algorithm that models delta processing as an uncertainty propagation problem, and minimizes the recomputation during each subsequent delta update by minimizing the uncertainties in the partial (including intermediate) query results. We implement iOLAP on top of Apache Spark and have successfully demonstrated it at scale on over $100$ machines. Extensive experiments on a multitude of queries and datasets demonstrate that iOLAP can deliver approximate query answers for complex OLAP queries orders of magnitude faster than a traditional OLAP engine,  while continuously delivering updates every few seconds.", 
    "subtype": "Research,", 
    "authors": [
      {
        "name": "Kai Zeng"
      }, 
      {
        "name": "Sameer Agarwal"
      }, 
      {
        "name": "Ion Stoica"
      }
    ], 
    "type": "Research,", 
    "id": "972"
  }
}